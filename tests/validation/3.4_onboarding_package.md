# Beta Tester Onboarding Package

## Overview

This document provides the comprehensive onboarding materials for beta testers. It includes summaries of key guides, feedback templates, and communication norms.

---

## Part 1: Essential Materials

### A. Quick Start Guide Reference

**Location:** `docs/quickstart.md` (complete guide, ~890 lines)

**Key sections for testers:**
1. **Phase 1-4:** Project setup and first-paper walkthrough (40-41 minutes total)
2. **Common Issues:** 10 documented failure modes with solutions
3. **Terminal Output Examples:** 23 validated examples showing expected output
4. **Time Tracking:** Phase breakdown showing expected duration per step

**TL;DR for Testers:**
- Read "Phase 1" for 5-minute project setup
- Use "Phase 2" step-by-step for your first paper (15-20 minutes)
- Reference "Common Issues" whenever stuck (most solve in 2-3 minutes)
- Expected first-paper time: 20-30 minutes (slows down with debugging)
- Subsequent papers: 5-10 minutes once you find your rhythm

**When to reference:**
- Before starting: Skim the phases overview
- First paper: Work through Phase 2 step-by-step with guide open
- Subsequent papers: Use phases as checklist
- If stuck: Jump to Common Issues matching your problem
- If issue not listed: Report to support (Discord/GitHub Discussions)

---

### B. Best Practices Guide Reference

**Location:** `docs/best-practices.md` (complete guide, ~1,420 lines)

**Key sections for testers:**

1. **Cost Estimation (Section 1):**
   - Budget calculator: $3-10 per project depending on paper count
   - Your project estimate: [Will be calculated during onboarding]
   - Explains token usage, Claude API pricing, how to track spend

2. **Prompt Optimization (Section 2):**
   - How to reduce token usage by 67% while maintaining accuracy
   - Useful for large projects or budget-conscious extraction
   - Advanced topic; not required for MVP testing

3. **Tool Selection (Section 3):**
   - When to use MAestro vs. traditional tools
   - MAestro is good for: exploratory meta-analysis, large literature reviews
   - Traditional tools better for: publication-grade precision work (for now)
   - Decision framework for your specific use case

4. **Data Quality (Section 4):**
   - Three-color labeling: üü¢ high-confidence, üü° medium, üî¥ low-confidence
   - Interpreting your extracted data: When is ‚â•80% green acceptable?
   - How to spot-check accuracy on a few papers manually

5. **Common Mistakes (Section 5):**
   - 10 failure modes from Epic 1-2 testing with workarounds
   - What to do if you hit these situations
   - How to report if you find new ones

6. **Performance & Advanced Topics (Sections 6-8):**
   - Team collaboration workflows (if testing with colleagues)
   - Community resources and escalation paths
   - Advanced discipline-specific guidance

**TL;DR for Testers:**
- Start with Section 3 (Tool Selection) to understand MAestro's scope
- Use Section 1 (Cost) to track your spending during testing
- Use Section 4 (Data Quality) to interpret your extraction results
- Reference Section 5 (Common Mistakes) if you hit unexpected issues

---

### C. Feedback Survey Templates

#### Weekly Lightweight Survey (5 minutes to complete)

**Timing:** Every Friday via email or Discord

**Questions:**

1. **What worked well this week?**
   - _Open text (1-3 sentences)_
   - Example: "The step-by-step guide made my first two papers quick. Microscope is really fast."

2. **What frustrated you or didn't work?**
   - _Open text (1-3 sentences)_
   - Example: "Table extraction failed on one paper. I had to manually type those values in."

3. **What features are missing or would help?**
   - _Open text (1-3 sentences)_
   - Example: "Would be great if we could batch-extract multiple papers at once instead of one at a time."

4. **Overall clarity/usefulness rating (this week):**
   - ‚≠ê 1 (confusing, not useful)
   - ‚≠ê 2 (unclear, hard to use)
   - ‚≠ê 3 (okay, some unclear parts)
   - ‚≠ê 4 (good, mostly clear)
   - ‚≠ê 5 (excellent, very clear)

5. **Papers extracted this week:**
   - Number: _____
   - Expected next week: _____

**Response deadline:** Monday morning (48-hour turnaround)

**Submission:** Reply to email or post in Discord #weekly-check-ins

---

#### End-of-Beta Comprehensive Survey (20 minutes to complete)

**Timing:** Last week of beta testing (Week 5-6 of onboarding)

**Instructions:** Complete this survey when you've finished extracting your 10-20 papers.

---

**Section A: Extraction Accuracy**

1. **How many papers did you extract in total?**
   - Number: _____

2. **For [3-5] of your papers, spot-check accuracy:**
   - Manually verify key data points (effect size, sample sizes, authors) from original PDF
   - Count how many fields match exactly between AI extraction and your manual check
   - Calculate accuracy percentage: (matching fields / total fields) √ó 100%
   - Report here: _____ % accuracy

3. **Did you notice any systematic accuracy problems?**
   - Example: "Table extraction always fails for multi-column layouts"
   - Open text response: _______________

4. **Overall assessment of extraction quality:**
   - ‚≠ê 1 (Mostly wrong, unreliable)
   - ‚≠ê 2 (Many errors, needs major revision)
   - ‚≠ê 3 (Mixed quality, some manual fixing needed)
   - ‚≠ê 4 (Good quality, minor fixes needed)
   - ‚≠ê 5 (Excellent, matches manual extraction)

---

**Section B: Time Savings**

5. **Time tracking: Minutes per paper**
   - For each of your 10-20 papers, you kept time logs (from weekly check-ins)
   - Calculate average: _____ minutes per paper

6. **Your baseline: How long does manual extraction typically take you?**
   - Minutes per paper: _____ (or hours per paper: _____)

7. **Time savings calculation:**
   - Baseline time: _____ minutes per paper
   - MAestro time: _____ minutes per paper
   - Time saved per paper: _____ minutes
   - Percentage saved: _____ %
   - Cumulative savings on your project: _____ hours

8. **Does this match your expectation?**
   - [ ] Better than expected (>50% savings)
   - [ ] As expected (~50% savings)
   - [ ] Less than expected (<50% savings)
   - [ ] Describe: _______________

---

**Section C: Usability & Clarity**

9. **How clear were the provided guides?** (Rate 1-5)

   | Aspect | Rating | Comments |
   |--------|--------|----------|
   | Quick Start Guide | ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ | __________ |
   | Best Practices Guide | ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ | __________ |
   | Weekly feedback templates | ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ | __________ |
   | Communication norms doc | ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ | __________ |
   | Troubleshooting section | ‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ | __________ |

10. **Did you need help outside the provided guides?**
    - Yes / No
    - If yes, what was the issue? _______________

11. **How responsive was the support team?**
    - [ ] Excellent (under 24 hours)
    - [ ] Good (24-48 hours)
    - [ ] Okay (48-72 hours)
    - [ ] Slow (over 72 hours)
    - [ ] Didn't need support

---

**Section D: Feature Requests & Bugs**

12. **List 1-3 features that would make MAestro more useful for your workflow:**
    1. _______________
    2. _______________
    3. _______________

13. **Bugs or errors you encountered:**
    - List each bug with:
      - What happened: _______________
      - When (which paper/phase): _______________
      - Severity (critical/major/minor): _______________
      - Workaround (if any): _______________
    - (If >5 bugs, list most important in order)

14. **Edge cases or unusual situations you hit:**
    - Example: "Very large paper (50 pages) caused extraction to be very slow"
    - Open text: _______________

---

**Section E: Testimonials & Recommendations**

15. **In your own words: Would you use MAestro for a real project (not just beta testing)?**
    - [ ] Yes, definitely
    - [ ] Yes, with improvements [list: _______________]
    - [ ] Maybe, depends on [_______________]
    - [ ] No, not yet
    - [ ] No, not suitable for my work

16. **Best quote (for our marketing/publication):**
    - What was the most valuable aspect of MAestro for you?
    - In 1-2 sentences: _______________
    - Permission to use this quote publicly: [ ] Yes [ ] No [ ] Anonymously only

17. **Would you recommend MAestro to a colleague?**
    - [ ] Yes, enthusiastically
    - [ ] Yes, with caveats [_______________]
    - [ ] Not yet, but interested to see improvements
    - [ ] No, not suitable

18. **Overall beta testing experience:**
    - How well did the onboarding package prepare you? (1-5) ‚≠ê
    - How clear was the testing objective? (1-5) ‚≠ê
    - How inclusive was the community/support? (1-5) ‚≠ê
    - Average: _____ / 5

---

**Section F: Demographics (Optional)**

19. **Your research discipline:** _______________
20. **Your career stage:** [ ] PhD Student [ ] Postdoc [ ] Faculty [ ] Other
21. **Geographic location (country/region):** _______________
22. **This is my [first/second/third+] time beta testing research tools:** _______________

---

**Thank you for your participation!** Your feedback is invaluable. We'll share aggregated results and your specific insights will directly influence Story 3.6 (Refinement) and beyond.

---

### D. Weekly Check-In Schedule & Format

**Timing:** Same day each week (suggest Friday afternoons or Monday mornings based on testers' preference)

**Duration:** 30 minutes (or 15 minutes for async)

#### Sync Call Format (Optional, 30 minutes)

**Agenda:**
1. **Opening (2 min):** How's the week going overall?
2. **What worked (5 min):** What was smoothest about extraction?
3. **Frustrations (8 min):** Where did you get stuck? (technical support)
4. **Feedback (10 min):** Bigger picture‚Äîanything we should know about?
5. **Next week (3 min):** How many papers will you extract? Any blockers to anticipate?
6. **Q&A (2 min):** Any final questions?

**Facilitator Notes:**
- Record call (with permission) for those who can't attend live
- Take screenshot-worthy quotes for testimonials
- Document any repeated issues (suggests docs need improvement)
- Send summary email within 24 hours

#### Async Check-In Format (Email-based, 5 minutes to respond)

**Subject:** Week [#] Check-in: [Tester Name]

**Body Template:**

```
Hi [Tester Name],

Quick check-in! Reply to these questions by Monday:

1. Papers extracted this week: ___
2. What worked well: _______________
3. What was frustrating: _______________
4. Anything blocking progress: _______________
5. On track for 10-20 papers total: Yes/No/Maybe

Looking forward to your feedback!
[Your name]
```

---

### E. Communication Norms Document

#### Response Time Expectations

| Type | Response Time | Channel |
|------|---|---|
| Bug reports | 24-48 hours | GitHub Discussions or Discord |
| General questions | 24-48 hours | GitHub Discussions or Discord |
| Urgent/blocking issues | 4-6 hours | Discord @mention or direct message |
| Feature requests | Weekly digest | Summarized in Friday check-in |

#### Bug Reporting Format

Use this template when reporting bugs to ensure we can help quickly:

```
**Title:** [Concise 1-line description]

**Steps to Reproduce:**
1. [First step]
2. [Second step]
3. [Etc.]

**Expected behavior:**
[What should have happened]

**Actual behavior:**
[What actually happened]

**Paper/context:**
[Paper title, author, year ‚Äî helps us reproduce]

**Severity:**
- [ ] Critical (completely blocked)
- [ ] Major (workaround available, but cumbersome)
- [ ] Minor (cosmetic or very rare)

**Workaround (if found):**
[How you worked around it, if applicable]
```

#### Feature Request Format

```
**Feature:** [Concise title]

**Problem it solves:**
[What's your current pain point?]

**Current workflow:**
[How do you do this now?]

**Proposed solution:**
[What would make this easier?]

**Priority for you:**
- [ ] Critical (blocks my project)
- [ ] Important (saves me significant time)
- [ ] Nice-to-have (would be cool)

**Use case:**
[Example: "I extract 50 papers at a time; one-by-one extraction is slow"]
```

#### Confidentiality & Data Handling

- **Your research data:** Stored locally on your machine. We never see your papers or extracted data.
- **Your feedback:** May be used in our documentation and publications (anonymously unless you opt-in publicly)
- **NDA:** If you have sensitive research, let us know. We can discuss confidentiality terms.
- **Anonymity:** All feedback can be shared anonymously; just note your preference in responses

#### Community Code of Conduct

1. **Be respectful:** Feedback is a gift, even if critical. We appreciate honest feedback.
2. **Be specific:** "This is confusing" is less helpful than "I expected X but got Y." Specific examples help us improve.
3. **No research data sharing:** Don't paste your actual research data in public channels. Use private messages for sensitive stuff.
4. **Support each other:** If you know the answer to a peer's question, help out! We're building a community.
5. **Have fun:** Beta testing should be interesting, not a chore. Celebrate wins, joke about bugs, enjoy the process.

---

## Part 2: Pre-Onboarding Checklist

**Send this to testers 1 week before onboarding call:**

**By [Date], please complete:**

- [ ] Create Claude account (or verify institutional access)
- [ ] Skim the Quick Start Guide (docs/quickstart.md) - 10-minute read
- [ ] Review the Beta Testing Goals section below - 5-minute read
- [ ] Prepare your test dataset:
  - [ ] Option A: Gather 10-20 papers from your own project
  - [ ] Option B: Use sample dataset (we'll provide link)
- [ ] Install MAestro CLI (instructions in Quick Start)
- [ ] Join communication channels:
  - [ ] GitHub Discussions: [Link]
  - [ ] Optional Discord: [Link]
- [ ] Complete tech setup survey (5 minutes):
  - "What's your Operating System?" (needed for troubleshooting)
  - "What terminal do you use?" (bash, PowerShell, zsh, other?)

---

## Part 3: Day 1 - Onboarding Call Agenda

**Duration:** 30-45 minutes

**Attendees:** All beta testers (or individual calls if group doesn't work)

**Slides/Materials:**
- Slide 1: Welcome & MAestro vision (2 min)
- Slide 2: What is beta testing? (3 min)
- Slide 3: Your role & timeline (5 min)
- Slide 4: Walkthrough of materials (10 min)
- Slide 5: Support & communication channels (5 min)
- Slide 6: Q&A (10 min)

**Talking Points:**

> "Thank you all for volunteering! MAestro is an AI-powered tool to extract data from research papers automatically. We're validating that it works across different disciplines and research methodologies. Your job is to be honest: Does it work? Where does it break? What would make it better?
>
> Over the next 4-6 weeks, you'll extract 10-20 papers. We're tracking three things: accuracy (does it match the papers?), time savings (how much faster is it?), and usability (is it easy to use?). Don't worry about publication-grade perfection; we're testing the tool, not your meta-analysis.
>
> We'll check in weekly, either sync call or async email, your choice. We'll cover: what worked, what frustrated you, what we should know. And we want to hear about bugs, feature ideas, edge cases, everything.
>
> You have support: guides, community chat, direct support. We aim for 24-48 hour response on questions. Anything blocking you, let us know immediately.
>
> This is MVP quality. Rough edges expected. We'll refinalize the tool based on your feedback. Your feedback directly shapes what we build next."

---

## Part 4: First-Paper Support

**Offer optional 1-on-1 calls for first paper** (to catch early friction)

**First-Paper Call Agenda (20 minutes):**
1. Screen share their setup (2 min)
2. Walk through Phase 2 of Quick Start (10 min)
3. Run first extraction together (5 min)
4. Troubleshoot if needed (3 min)
5. Check their comfort level (0 min)

**Alternative: Office Hours**
- If you don't want 1-on-1 calls, offer group office hours first week
- Example: "Monday 2pm PT, optional open office hours on Zoom, ask any questions"
- Takers can drop in anytime during the hour

---

## File Structure for Delivery

Place these materials in a folder testers will receive:

```
MAestro_Beta_Onboarding_Package/
‚îÇ
‚îú‚îÄ‚îÄ üìñ WELCOME.txt
‚îÇ   (Simple text: "Start here ‚Üí Read the materials below, then join Discord/Discussions")
‚îÇ
‚îú‚îÄ‚îÄ üìã ESSENTIAL_MATERIALS.md
‚îÇ   (This document, Part 1: Quick links to guides, survey templates, norms)
‚îÇ
‚îú‚îÄ‚îÄ üìÖ WEEKLY_CHECKIN_SCHEDULE.txt
‚îÇ   (Template for scheduling; e.g., "Friday 2pm PT, 30 min sync or async email")
‚îÇ
‚îú‚îÄ‚îÄ üìä FEEDBACK_SURVEYS/
‚îÇ   ‚îú‚îÄ‚îÄ weekly_survey_template.txt
‚îÇ   ‚îî‚îÄ‚îÄ end_of_beta_survey.txt
‚îÇ
‚îú‚îÄ‚îÄ üîó EXTERNAL_LINKS.txt
‚îÇ   (Clickable links to:
‚îÇ    - docs/quickstart.md
‚îÇ    - docs/best-practices.md
‚îÇ    - GitHub Discussions
‚îÇ    - Discord invite
‚îÇ    - Sample project folder)
‚îÇ
‚îî‚îÄ‚îÄ üìû SUPPORT_CONTACTS.txt
    (How to reach you; response time commitments)
```

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2025-10-24 | Initial onboarding package with all materials, survey templates, and support structures |

---

**This package is ready for distribution to beta testers on [Onboarding Date].**
