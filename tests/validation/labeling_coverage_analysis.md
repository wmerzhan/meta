# Three-Color Labeling Coverage Analysis

<!-- Powered by BMADâ„¢ Core -->

**Story:** 1.6 - Test Microscope with Sample Papers
**Purpose:** Measure ðŸŸ¢ðŸŸ¡ðŸ”´ labeling coverage and patterns (AC #4)
**Goal:** Establish baseline labeling statistics for Microscope v1.0

## Three-Color Labeling System

- ðŸŸ¢ **Green (Direct Quote):** Value directly observed in paper with page reference
- ðŸŸ¡ **Yellow (Computed):** Value calculated/inferred with documented calculation
- ðŸ”´ **Red (Uncertain):** Missing or uncertain data with explanation

**Target:** 90%+ of uncertain data should be flagged with ðŸ”´ labels

## Per-Paper Coverage

| Paper ID | Total Data Points | ðŸŸ¢ Count | ðŸŸ¢ % | ðŸŸ¡ Count | ðŸŸ¡ % | ðŸ”´ Count | ðŸ”´ % | Notes |
|----------|------------------|---------|------|---------|------|---------|------|-------|
| _Example: smith_2023_ | _45_ | _18_ | _40%_ | _15_ | _33%_ | _12_ | _27%_ | _High quality paper_ |
|  |  |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |  |  |

## Aggregate Statistics

_Across all papers:_

- **Total data points extracted:** [N]
- **Mean ðŸŸ¢ percentage:** [X%] (SD: [Y%])
- **Mean ðŸŸ¡ percentage:** [X%] (SD: [Y%])
- **Mean ðŸ”´ percentage:** [X%] (SD: [Y%])

### Distribution Summary

```
Expected distribution (hypothetical):
ðŸŸ¢ Green:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 40-50%  (direct observations)
ðŸŸ¡ Yellow: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 25-35%  (computed values)
ðŸ”´ Red:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 20-30%  (uncertainties)
```

## Coverage by Paper Characteristics

### By Reporting Quality

| Quality Level | Mean ðŸŸ¢% | Mean ðŸŸ¡% | Mean ðŸ”´% | Count |
|--------------|---------|---------|---------|-------|
| High |  |  |  | [N] |
| Medium |  |  |  | [N] |
| Low |  |  |  | [N] |

**Expected pattern:** Low-quality papers should have higher ðŸ”´% (more missing data)

### By Study Design

| Design | Mean ðŸŸ¢% | Mean ðŸŸ¡% | Mean ðŸ”´% | Count |
|--------|---------|---------|---------|-------|
| Simple RCT |  |  |  | [N] |
| Complex RCT |  |  |  | [N] |
| Quasi-experimental |  |  |  | [N] |
| Other |  |  |  | [N] |

### By Discipline

| Discipline | Mean ðŸŸ¢% | Mean ðŸŸ¡% | Mean ðŸ”´% | Count |
|-----------|---------|---------|---------|-------|
| Medicine |  |  |  | [N] |
| Psychology |  |  |  | [N] |
| Education |  |  |  | [N] |
| Other |  |  |  | [N] |

## Label Evidence Quality

For each label type, assess if evidence is provided:

### ðŸŸ¢ Green Label Evidence

- **Total ðŸŸ¢ labels:** [N]
- **With page reference:** [N] ([X%])
- **With section reference:** [N] ([X%])
- **Missing evidence:** [N] ([X%])

**Quality assessment:** [Pass/Fail - should be >95% with evidence]

### ðŸŸ¡ Yellow Label Evidence

- **Total ðŸŸ¡ labels:** [N]
- **With calculation shown:** [N] ([X%])
- **With source pages:** [N] ([X%])
- **Missing evidence:** [N] ([X%])

**Quality assessment:** [Pass/Fail - should be >95% with evidence]

### ðŸ”´ Red Label Evidence

- **Total ðŸ”´ labels:** [N]
- **With explanation:** [N] ([X%])
- **With impact note:** [N] ([X%])
- **Missing evidence:** [N] ([X%])

**Quality assessment:** [Pass/Fail - should be >90% with evidence]

## Uncertainty Flagging Effectiveness

**Goal:** 90%+ of uncertain/missing data should be flagged with ðŸ”´

**Validation method:** Compare against gold standard extractions

_For papers with gold standards:_

| Paper ID | True Uncertain Data (Gold Std) | ðŸ”´ Labels Applied | Flagging Rate |
|----------|-------------------------------|------------------|---------------|
| [paper_1] | [N items] | [N labels] | [X%] |
| [paper_2] | [N items] | [N labels] | [X%] |
| [paper_3] | [N items] | [N labels] | [X%] |

**Overall flagging effectiveness:** [X%] (target: >90%)

## Label Misclassification Analysis

_Based on gold standard comparison:_

**Common misclassifications:**
- ðŸŸ¢ used when should be ðŸŸ¡: [N cases] - _Example: Calculated values marked as direct quotes_
- ðŸŸ¡ used when should be ðŸŸ¢: [N cases] - _Example: Directly reported values marked as computed_
- ðŸ”´ used when should be ðŸŸ¢/ðŸŸ¡: [N cases] - _Example: Available data marked as uncertain_
- Missing ðŸ”´ when should be flagged: [N cases] - _Example: Missing data not flagged_

**Misclassification rate:** [X%] (lower is better)

## Observations

_Document patterns and insights:_

- Are labels consistently applied across papers?
- Do certain data types have predictable label patterns?
- Are computed effect sizes always labeled ðŸŸ¡?
- Are baseline characteristics with missing SDs labeled ðŸ”´?
- Is evidence quality consistent?

## Recommendations

_Based on coverage analysis:_

- Should prompt provide more explicit label selection guidance?
- Are there data types that frequently get mislabeled?
- Should evidence requirements be strengthened?
- What labeling patterns should be documented for users?

## Baseline for Future Comparison

These statistics establish **Microscope v1.0 baseline** for:
- Expected labeling distribution
- Evidence quality standards
- Uncertainty flagging effectiveness

Future prompt versions (v1.1+) should maintain or improve these metrics.
