# Beta Tester Recruitment Strategy

## Overview

This document defines the recruitment, selection, and onboarding strategy for MAestro MVP validation phase. The goal is to recruit 5-10 diverse beta testers over a 4-week recruitment window, with a documented contingency plan for extended solo testing if recruitment targets are not met.

---

## Recruitment Timeline

### Week 1: Launch Outreach (Days 1-7)

**Goal:** Initiate contact with all recruitment channels

- **Personal Network (Days 1-3)**
  - Identify 10-15 potential candidates from prior collaborations
  - Draft personalized recruitment emails
  - Send initial outreach by Day 3
  - Expected response time: 2-3 days

- **Academic Twitter (Days 1-2)**
  - Craft recruitment tweet/thread explaining MAestro and beta opportunity
  - Post on Day 2, monitor engagement
  - Respond to initial inquiries within 24 hours

- **Reddit Communities (Days 2-3)**
  - Prepare recruitment posts for r/AcademicPsychology, r/Scholar, r/Science
  - Post to communities Day 3 afternoon
  - Monitor and respond to comments throughout the week

- **Meta-analysis Mailing Lists (Days 3-5)**
  - Contact list moderators: Cochrane, Campbell, discipline-specific lists
  - Request permission to post recruitment message
  - Post approved messages by Day 5

**Expected Yields Week 1:** 5-8 initial interest responses

### Week 2: Follow-up & Screening (Days 8-14)

**Goal:** Convert interested candidates to screened applicants

- **Day 8-10:** Follow up with personal network candidates who haven't responded
- **Day 11-14:** Begin sending screening questionnaires to interested candidates
- **Ongoing:** Monitor social media mentions and Reddit discussions
- **Daily:** Respond to inquiries within 24 hours

**Expected Progress:** 6-10 candidates in screening pipeline

### Week 3: Selection & Interviews (Days 15-21)

**Goal:** Finalize beta tester roster

- **Day 15-17:** Collect screening questionnaire responses
- **Day 18-20:** Schedule and conduct brief interviews with top candidates
- **Day 20-21:** Make final selection decisions
- **Confirm diverse cohort:** Check for discipline, career stage, and technical comfort level variety

**Expected Outcome:** 5-10 testers confirmed by end of Week 3

### Week 4: Decision Point & Contingency (Days 22-28)

**Goal:** Assess recruitment success and activate contingency if needed

- **Day 22:** Count recruited testers
- **Decision:**
  - **If ≥5 testers:** Proceed with planned beta testing (move to Onboarding Week 5)
  - **If <5 testers:** Trigger contingency plan (extended solo testing)

- **Contingency action (if <5):**
  - Document recruitment decision
  - Begin extended solo testing with 20+ diverse papers
  - Adjust timeline: solo testing extends to 6-8 weeks total
  - Proceed to Story 3.5 (Conduct Validation Studies) with solo test data

### Week 5: Onboarding (Days 29-35)

**Goal:** Complete beta tester onboarding

- **Day 29-30:** Send onboarding packages
- **Day 31:** Conduct group onboarding call (or individual calls if group doesn't work)
- **Day 32-35:** Support for first papers, answer questions

---

## Recruitment Channels & Contact Strategy

### 1. Personal Network (Target: 2-4 recruits)

**Approach:** Personalized direct outreach

**Email Template:**
```
Subject: Beta test MAestro—cutting-edge meta-analysis tool

Hi [Name],

I'm launching private beta testing for MAestro, a new tool that uses AI to automate data extraction for meta-analyses. You came to mind because of your work on [specific research topic/method].

I'm looking for 5-10 beta testers to validate the tool and provide feedback. Commitment: 10-20 hours over 4-6 weeks, mainly extracting 10-20 papers from your own project or a sample project.

What's in it for you?
- Early access to a tool that could save you 50%+ time on literature extraction
- Credit as a beta tester
- Direct influence on what gets built next

Interested? Reply with any questions, or let me know if you'd like to schedule a brief call.

Looking forward!
[Your name]
```

**Candidate Sources:**
- PhD advisors / postdoc mentors
- Collaborators on past projects
- Colleagues from conferences or academic communities
- Research lab members

### 2. Academic Twitter (Target: 1-3 recruits)

**Hashtags to Monitor:** #MetaAnalysis #SystematicReview #AcademicResearch #ResearchMethods

**Tweet Template:**
```
🧪 Looking for 5-10 beta testers for MAestro—a new AI-powered meta-analysis tool.

Extract data from papers 50%+ faster while maintaining quality & accuracy.

Commitment: 10-20 hours over 4-6 weeks
Get early access + shape what we build next
All career stages & disciplines welcome

DM for details or reply here! 🔍📊
```

**Engagement Strategy:**
- Reply to relevant research conversations
- Like and retweet meta-analysis methodology discussions
- Share behind-the-scenes tool development updates
- Use thread format to explain value prop in detail

### 3. Reddit Communities (Target: 1-2 recruits)

**Communities:**
- r/AcademicPsychology (2,000+ members)
- r/Scholar (100,000+ members)
- r/Science (research methodology discussions)

**Post Template:**
```
[Project] Looking for beta testers: MAestro—AI-powered meta-analysis extraction tool

Hi researchers! We're launching a private beta for MAestro, an AI-powered tool that automates data extraction from research papers for meta-analyses.

**What we're looking for:**
- 5-10 researchers with active meta-analysis projects
- Commitment: 10-20 hours over 4-6 weeks
- Willingness to provide detailed feedback

**What you get:**
- Early access to a tool that could save you hours on literature extraction
- Credit as beta tester
- Direct input on what we build next

**About the tool:**
- Extract structured data (effect sizes, sample sizes, study design) from PDFs
- 50%+ time savings vs. manual extraction
- Works across disciplines (medicine, psychology, education, economics, etc.)

Interested? Comment below or DM me. Happy to answer any questions!
```

### 4. Meta-Analysis Mailing Lists (Target: 2-4 recruits)

**Lists to Contact:**
- Cochrane Collaboration members list
- Campbell Collaboration members list
- Meta-analysis methodology groups
- Discipline-specific research networks:
  - American Psychological Association (research methods)
  - Epidemiology methods groups
  - Education research networks
  - Economics research associations

**Outreach Strategy:**
- Email list moderators 2 weeks in advance requesting permission to post
- Submit message for moderator approval
- Post approved messages to 3-5 lists

**Mailing List Post Template:**
```
BETA TESTING: MAestro—AI-powered meta-analysis tool

Dear [List Members],

We are recruiting 5-10 beta testers for MAestro, a new AI-powered tool designed to automate data extraction for meta-analyses and systematic reviews.

**Ideal candidates:**
- Researchers with active meta-analysis or systematic review projects
- Willing to commit 10-20 hours over 4-6 weeks for testing and feedback
- All career stages and technical backgrounds welcome

**What we're validating:**
- Extraction accuracy (target: ≥90% agreement with manual extraction)
- Time savings (target: 50%+ reduction vs. manual approach)
- Usability across disciplines and research methodologies
- Edge cases and failure modes

**What beta testers receive:**
- Early access to the tool
- Cost support (API credits provided)
- Credit and acknowledgment in project documentation
- Direct influence on product roadmap

**Time commitment breakdown:**
- ~5 min per paper for AI extraction
- ~30 min per week for feedback and check-ins
- 10-20 papers total over 4-6 weeks

Interested in participating? Contact [your email] with subject line: "Beta Tester Interest"

More information: [link to docs/quickstart.md]

Best regards,
[Your name & affiliation]
```

---

## Success Metrics

### Recruitment Success (Primary)
- **Target:** 5-10 confirmed beta testers by end of Week 4
- **Minimum threshold:** 5 testers (contingency triggered if <5)
- **Tracking:** Weekly count of recruits vs. timeline

### Diversity Achievement (Secondary)
- **Disciplines:** At least 3 different research fields represented
- **Career stages:** Mix of PhD students, postdocs, junior faculty
- **Technical comfort:** Representation across beginner, intermediate, advanced levels
- **Geographic:** International representation encouraged

### Quality of Recruits (Tertiary)
- **Commitment:** All testers confirm 10-20 hour availability
- **Motivation:** Testers have active projects or strong interest in tool validation
- **Responsiveness:** Quick responses to screening questionnaire and scheduling

---

## Contingency Plan (AC9)

### Trigger Condition
Fewer than 5 testers recruited by end of Week 4

### Pivot Strategy: Extended Solo Testing

**Timeline:** Weeks 4-11 (7-8 weeks of intensive testing)

**Scope:** 20+ diverse papers across 5+ disciplines

**Paper Selection Criteria:**
- **Disciplines:** Medical (cancer research, systematic reviews), Psychology (behavioral interventions), Education (learning sciences), Social Sciences (policy impact), Economics (health economics)
- **Sample sizes:** Mix from small (n=50) to large (n=1000+)
- **Effect size metrics:** HR, OR, RR, MD, SMD, correlation coefficient
- **Edge cases:** Missing data, heterogeneous populations, complex statistical reporting
- **Paper complexity:** 8-50 pages (test context window handling)

**Testing Protocol:**
1. Extract data from all 20+ papers using Microscope
2. Document accuracy by spot-checking 5-10 papers manually
3. Log time per paper to measure time savings
4. Test edge cases systematically
5. Identify failure modes and document workarounds
6. Create comprehensive validation report

**Success Criteria (Solo Testing Equivalent):**
- ≥90% accuracy on spot-checked papers
- ≥50% time savings vs. manual extraction (from your baseline experience)
- 10-20 documented failure modes with severity/workaround info
- Comprehensive discipline coverage (5+ fields tested)
- All tests documented in validation report

**Justification for Contingency:**
- MVP validation still achievable through rigorous solo testing
- Addresses risk: insufficient diversity of real-world projects
- Maintains timeline: 6-8 weeks still acceptable for MVP validation
- Preserves quality: methodical testing with diverse papers provides strong signal
- Supports Story 3.5 (Validation Studies) with solid data

---

## Decision Framework

Use this flowchart during Week 4 to decide path forward:

```
Week 4: Recruitment Assessment
│
├─ Recruited ≥5 testers?
│  │
│  ├─ YES → Proceed with beta testing
│  │         Task 8: Execute Recruitment (complete)
│  │         Task 9: Screen & Select (complete)
│  │         Task 11: Onboard Beta Testers (Week 5)
│  │         Task 12: Monitor Progress (Weeks 5+)
│  │
│  └─ NO (< 5 testers) → Trigger Contingency
│                        Document decision
│                        Begin solo testing (20+ papers)
│                        Extend timeline to Week 11
│                        Create solo validation report
│                        Proceed to Story 3.5 with solo data
```

---

## Communication Plan

### Pre-Recruitment (Before Week 1)
- Update README.md with beta program announcement
- Prepare email templates and social media posts
- Set up GitHub Discussions for community channel

### During Recruitment (Weeks 1-4)
- Post weekly recruitment status (optional Twitter updates)
- Monitor and respond to all inquiries within 24 hours
- Send progress updates to confirmed recruits

### At Decision Point (End of Week 4)
- Document final recruitment outcome
- Activate contingency plan if needed
- Communicate timeline adjustment to any partial recruits

### During Onboarding (Week 5)
- Send detailed onboarding package
- Host onboarding call
- Provide first-paper support

---

## Resource Requirements

- **Time commitment:** 5-10 hours for recruitment/messaging
- **Tools:** Email, social media, GitHub Discussions, Zoom (optional)
- **Budget:** $0 (contingent recruitment only)
- **External dependencies:** None (all channels are free)

---

## Approval & Tracking

- **Story Owner:** You (founder)
- **Timeline:** Weeks 1-4 (recruitment), Week 5 (onboarding)
- **Success Trigger:** 5+ confirmed testers OR contingency plan activated
- **Review Date:** End of Week 4

---

**Version:** 1.0
**Created:** 2025-10-24
**Last Updated:** 2025-10-24
