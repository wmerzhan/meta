# MAestro Architecture Document

**Version:** 0.1
**Last Updated:** 2025-10-19
**Author:** Winston (Architect Agent)

---

## Table of Contents

1. [Introduction](#introduction)
2. [High Level Architecture](#high-level-architecture)
3. [Tech Stack](#tech-stack)
4. [Data Models](#data-models)
5. [Components](#components)
6. [External APIs](#external-apis)
7. [Core Workflows](#core-workflows)
8. [Database Schema](#database-schema)
9. [Source Tree](#source-tree)
10. [Infrastructure and Deployment](#infrastructure-and-deployment)
11. [Error Handling Strategy](#error-handling-strategy)
12. [Coding Standards](#coding-standards)
13. [Test Strategy and Standards](#test-strategy-and-standards)
14. [Security](#security)

---

## Introduction

This document outlines the overall project architecture for **MAestro**, including backend systems, shared services, and non-UI specific concerns. Its primary goal is to serve as the guiding architectural blueprint for AI-driven development, ensuring consistency and adherence to chosen patterns and technologies.

**Relationship to Frontend Architecture:**
MAestro's CROS phase includes a VS Code Extension with a conversational UI. A separate Frontend Architecture Document may be created to detail the frontend-specific design, which MUST be used in conjunction with this document. Core technology stack choices documented herein (see "Tech Stack") are definitive for the entire project, including any frontend components.

### Starter Template or Existing Project

Based on the PRD and project context, MAestro is a **greenfield project** with a unique architectural approach:

**MVP Phase:** No traditional starter template applies. The system is a collection of markdown prompt templates stored in a Git repository. There's no application to "start" - users directly interact with Claude Code using the prompts.

**CROS Phase:** The project will build:
1. **Python CLI** - A command-line interface tool distributed via PyPI
2. **VS Code Extension** - A conversational interface integrated into VS Code

**Decision:** N/A for MVP (pure markdown templates). For CROS phase, individual project scaffolding tools will be used as needed.

### Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-19 | v0.1 | Initial architecture document draft | Winston (Architect) |

---

## High Level Architecture

### Technical Summary

MAestro employs a **dual-phase evolutionary architecture** that transitions from pure prompt-based workflows (MVP) to a local-first desktop application (CROS). The MVP phase consists of version-controlled markdown prompt templates executed directly through Claude Code with zero application infrastructure. The CROS phase introduces a **local monolithic application** comprising a Python CLI (distributed via PyPI) and a VS Code Extension (distributed via VS Code Marketplace), both interacting with the Anthropic Claude API for AI-powered Meta-analysis workflows. All user data remains local (filesystem + SQLite), implementing **data card microservice architecture** where individual markdown files serve as atomic data units. This architecture achieves the PRD's 50% time reduction goal through conversation-driven automation while maintaining academic rigor via the three-color source labeling transparency system (ğŸŸ¢ğŸŸ¡ğŸ”´).

### High Level Overview

**1. Architectural Style:**

**MVP Phase:** **Template-Driven Stateless Workflow**
- No application server, no persistent state beyond filesystem
- Users manually execute prompt templates via Claude Code CLI/Desktop
- Pure markdown I/O with Git as version control system

**CROS Phase:** **Local Monolithic Desktop Application**
- Python CLI: Command-line orchestrator for batch operations and automation
- VS Code Extension: Conversational UI with rich text editing and visualization
- SQLite: Local metadata store (project configs, conversation history, logs, metrics)
- Filesystem: Primary data store (markdown data cards, CSV compilations, analysis outputs)

**Why Monolithic over Microservices:**
- Local-first mandate eliminates network latency concerns
- Simpler deployment (single PyPI package, single VSIX extension)
- Easier debugging with unified codebase
- Academic researcher users prefer "install and run" simplicity
- Scale target (10-100 papers) doesn't justify distributed complexity

**2. Repository Structure:**

**Monorepo** containing:
- **prompts/**: Microscope, Compiler, Oracle templates (MVP deliverables)
- **modules/**: Discipline-specific quality assessment frameworks
- **templates/**: Data card format, RAAA appendix scaffolding
- **docs/**: Quick Start, Best Practices, methodology documentation
- **tools/cli/**: Python CLI application (CROS Phase 1)
- **tools/vscode-extension/**: TypeScript VS Code extension (CROS Phase 2)
- **tests/**: Validation datasets, benchmark papers, automated tests
- **examples/**: Sample Meta-analysis projects

**3. Service Architecture:**

**MVP: No Services Architecture**
```
User (Terminal) â†’ Claude Code CLI â†’ Claude API â†’ Markdown File Output
                     â†“
                  Filesystem (Git Repo)
```

**CROS: Local Application Architecture**
```
User Interface Layer:
  - Python CLI (Click/Typer) â†’ Terminal I/O
  - VS Code Extension (TypeScript) â†’ Webview UI + Editor Integration

Application Layer:
  - CROS Core (Python): Workflow orchestration, prompt management, validation
  - Claude Code Integration: AI model calls managed by Claude Code

Data Layer:
  - SQLite: Project metadata, conversation logs, user preferences
  - Filesystem: Data cards (.md), compilations (.csv), analyses (.R/.py)
```

**4. Primary User Flow (CROS Phase):**

**Microscope Workflow:** User initiates â†’ CROS generates prompt â†’ User runs in Claude Code â†’ CROS validates & saves data card

**Compiler Workflow:** User requests compilation â†’ CROS aggregates data cards â†’ Generates CSV with quality report

**Oracle Workflow:** User asks statistical question â†’ CROS generates prompt â†’ Claude generates code â†’ User executes in R/Python

**5. Key Architectural Decisions & Rationale:**

| Decision | Rationale |
|----------|-----------|
| **Local-first (no cloud backend)** | Academic data privacy requirements; avoids PHI/PII concerns; works offline |
| **Filesystem as primary data store** | Git-compatible; human-readable; supports manual editing/validation |
| **SQLite for metadata only** | Lightweight, zero-config; filesystem remains source of truth |
| **Markdown data cards** | Version-controllable, readable without tools, compatible with academic publishing |
| **Dual distribution (PyPI + VS Code)** | Serves CLI power users AND GUI-preferring researchers |
| **Python 3.9+ for CLI** | Research community familiarity; rich ecosystem; type hints for maintainability |
| **TypeScript for Extension** | Required by VS Code API; type safety for complex UI |
| **Monorepo structure** | Simplifies coordination; shared examples/tests; atomic versioning |

### High Level Project Diagram

```mermaid
graph TB
    subgraph "User Environment (Local Machine)"
        User[ğŸ‘¤ Researcher]
        Terminal[Terminal/Claude Code CLI]
        VSCode[VS Code + MAestro Extension]

        subgraph "MAestro CROS Application"
            CLI[Python CLI<br/>Click/Typer]
            Extension[VS Code Extension<br/>TypeScript]
            Core[CROS Core<br/>Workflow Orchestration]
            Prompts[Prompt Templates<br/>Microscope/Compiler/Oracle]
            Validator[Schema Validator<br/>Data Quality Checker]
        end

        subgraph "Local Data Storage"
            FS[Filesystem<br/>Data Cards, CSV, Code]
            DB[(SQLite<br/>Metadata, Logs, Config)]
            Git[Git Repository<br/>Version Control]
        end

        User -->|CLI commands| Terminal
        User -->|Conversational UI| VSCode
        Terminal --> CLI
        VSCode --> Extension
        CLI --> Core
        Extension --> Core
        Core --> Prompts
        Core --> Validator
        Core -->|Read/Write| FS
        Core -->|Query/Insert| DB
        FS -.->|Tracks changes| Git

    end

    subgraph "External Services"
        Claude[Claude Code<br/>AI Model Calls]
    end

    Core -.->|User manually runs prompts| Claude
    Claude -.->|Responses| User

    style User fill:#e1f5ff
    style Claude fill:#fff4e1
    style FS fill:#e8f5e9
    style DB fill:#e8f5e9
    style Core fill:#f3e5f5
```

### Architectural and Design Patterns

#### Pattern 1: Template-Driven Workflow Orchestration
**Description:** Prompts are first-class architectural components stored as versioned templates with metadata (compatible models, creation date, version). CROS loads templates dynamically, injects user context, and tracks which template version was used for reproducibility.

**Rationale:** Enables RAAA (Reproducible AI-Assisted Analysis) requirement; allows prompt evolution without code changes; supports academic transparency standards.

#### Pattern 2: Data Card Microservice Architecture
**Description:** Each research paper's extracted data lives in an independent markdown file with YAML frontmatter (metadata) and markdown tables (data). Files are atomic units that can be created, validated, versioned, and compiled independently.

**Rationale:** Aligns with Git workflows; enables parallel extraction by teams; supports manual correction/validation; failed extractions don't corrupt project state.

#### Pattern 3: Three-Color Source Labeling System
**Description:** Every extracted data point tagged with ğŸŸ¢ (direct quote + evidence), ğŸŸ¡ (computed inference + calculation shown), or ğŸ”´ (uncertain/missing + explanation). Labels propagate through Compiler to final dataset.

**Rationale:** Core differentiator for academic credibility; enables data quality-aware statistical analysis; supports PRD requirement for 90%+ uncertain data flagging.

#### Pattern 4: Local-First with Cloud Augmentation
**Description:** All user data (papers, data cards, analyses) stored locally. Only prompts + paper text sent to Claude API via Claude Code. No MAestro-managed API keys.

**Rationale:** Meets academic data privacy standards; works offline (except extraction step); avoids vendor lock-in; reduces API costs.

#### Pattern 5: Dual Interface Pattern (CLI + Extension)
**Description:** Python CLI provides scriptable automation for power users. VS Code Extension provides conversational UI for interactive workflows. Both share CROS Core via different entry points.

**Rationale:** Serves diverse user base; VS Code extension leverages existing researcher tooling; allows phased development.

#### Pattern 6: Stateless Validation with Schema-Driven Contracts
**Description:** Data card format defined by JSON schema. Compiler and Oracle validate inputs against schema before processing. Validation errors surface immediately with actionable messages.

**Rationale:** Prevents garbage-in-garbage-out; enables early failure; supports PRD's "90%+ agreement with expert extraction" goal.

#### Pattern 7: Conversation Memory with SQLite
**Description:** CROS maintains lightweight conversation history in SQLite (user queries, AI responses, context windows used). Enables "resume workflow" and "refine previous extraction" features.

**Rationale:** Bridges MVP (stateless) to CROS vision (stateful sessions); reduces token costs; improves UX.

---

## Tech Stack

âš ï¸ **CRITICAL SECTION - Single Source of Truth for All Technology Decisions**

### Cloud Infrastructure

**MAestro is a LOCAL-FIRST application with NO traditional cloud infrastructure.**

- **Provider:** N/A (Local Desktop Application)
- **Key External Services:** Claude Code (user's installation)
- **Deployment Model:** Desktop distribution via PyPI (Python CLI) and VS Code Marketplace (Extension)
- **Data Residency:** All research data stored on user's local machine (filesystem + SQLite)

### Technology Stack Table

| Category | Technology | Version | Purpose | Rationale |
|----------|-----------|---------|---------|-----------|
| **Python Runtime** | Python | 3.9+ | CROS CLI runtime and core logic | 3.9 minimum for type hinting improvements; research community standard |
| **Python Package Manager** | Poetry | 1.8+ | Dependency management and packaging | Modern pyproject.toml standard; lockfile for reproducibility |
| **CLI Framework** | Typer | 0.12+ | Command-line interface framework | Built on Click; automatic help generation; Rich integration |
| **Terminal UI** | Rich | 13.7+ | Terminal formatting and progress displays | Beautiful tables, progress bars, syntax highlighting |
| **Python Type Checking** | mypy | 1.9+ | Static type analysis | PRD requirement for code quality; catches bugs pre-runtime |
| **Python Testing** | pytest | 8.0+ | Unit and integration testing | Industry standard; fixture support; excellent plugin ecosystem |
| **Data Validation** | Pydantic | 2.6+ | Schema validation for data cards | Type-safe data models; JSON schema generation; clear validation errors |
| **DataFrame Library** | pandas | 2.2+ | CSV compilation and data manipulation | Research community standard; compatibility with statistical tools |
| **YAML Parser** | PyYAML | 6.0.1+ | Data card frontmatter parsing | Standard YAML library; safe_load for security |
| **Markdown Parser** | python-markdown | 3.6+ | Data card table extraction | Parse markdown tables to structured data |
| **Local Database** | SQLite | 3.45+ (stdlib) | Project metadata, logs, conversation history | Zero-config; file-based; ACID transactions |
| **VS Code Extension Runtime** | Node.js | 20.11.0 LTS | VS Code extension JavaScript runtime | VS Code requirement; LTS for stability |
| **VS Code Extension Language** | TypeScript | 5.4+ | Extension development language | VS Code Extension API requirement; type safety |
| **VS Code Extension Build** | esbuild | 0.20+ | Fast TypeScript bundling | 100x faster than webpack; VS Code recommended |
| **VS Code Extension Testing** | @vscode/test-electron | 2.3+ | Extension integration testing | Official testing harness; runs in VS Code instance |
| **Git** | Git | 2.40+ | Version control for data cards and prompts | Research community standard; collaboration support |
| **Documentation** | MkDocs | 1.5+ | Static site generation for docs | Material theme; markdown-native; GitHub Pages deployment |
| **Code Formatting (Python)** | black | 24.0+ | Automated Python formatting | Opinionated; eliminates bikeshedding; PEP 8 compliant |
| **Code Linting (Python)** | ruff | 0.3+ | Fast Python linter | 10-100x faster than flake8; comprehensive rules |
| **Code Formatting (TS)** | prettier | 3.2+ | Automated TypeScript/JSON formatting | Opinionated; integrates with VS Code |
| **Code Linting (TS)** | eslint | 8.57+ | TypeScript linter | VS Code ecosystem standard; type-aware rules |
| **CI/CD** | GitHub Actions | N/A (latest) | Automated testing and publishing | Free for open source; cross-platform testing |
| **License** | MIT | N/A | Open source license | Maximum academic reuse; research community expectation |

---

## Data Models

MAestro çš„æ ¸å¿ƒæ•°æ®æ¨¡å‹åŸºäº **Data Card Microservice Architecture**ï¼Œæ¯ä¸ªç ”ç©¶è®ºæ–‡çš„æ•°æ®ä»¥ç‹¬ç«‹ markdown æ–‡ä»¶å½¢å¼å­˜å‚¨ã€‚

### Model 1: DataCard (æ•°æ®å¡ç‰‡)

**Purpose:** è¡¨ç¤ºå•ç¯‡ç ”ç©¶è®ºæ–‡çš„å®Œæ•´æ•°æ®æå–ç»“æœï¼ŒåŒ…æ‹¬å…ƒæ•°æ®ã€è´¨é‡è¯„ä¼°å’Œæå–çš„æ•°æ®ç‚¹ã€‚

**Key Attributes:**
- `study_id`: String - å”¯ä¸€æ ‡è¯†ç¬¦
- `title`: String - è®ºæ–‡æ ‡é¢˜
- `authors`: List[String] - ä½œè€…åˆ—è¡¨
- `year`: Integer - å‘è¡¨å¹´ä»½
- `doi`: String (optional) - æ•°å­—å¯¹è±¡æ ‡è¯†ç¬¦
- `extraction_date`: DateTime - æ•°æ®æå–æ—¥æœŸ
- `extractor`: String - æå–è€…å§“åæˆ–ID
- `microscope_version`: String - ä½¿ç”¨çš„ Microscope prompt ç‰ˆæœ¬
- `claude_model`: String - ä½¿ç”¨çš„ Claude æ¨¡å‹ç‰ˆæœ¬
- `screening_decision`: Enum["include", "exclude"] - ç­›é€‰å†³å®š
- `quality_scores`: Dict[String, Any] - è´¨é‡è¯„ä¼°åˆ†æ•°
- `extracted_data`: List[DataPoint] - æå–çš„æ•°æ®ç‚¹åˆ—è¡¨

**Relationships:**
- å±äºä¸€ä¸ª Projectï¼ˆé€šè¿‡æ–‡ä»¶ç³»ç»Ÿè·¯å¾„å…³è”ï¼‰
- åŒ…å«å¤šä¸ª DataPointï¼ˆåµŒå¥—ç»“æ„ï¼‰
- å¼•ç”¨ä¸€ä¸ª PromptTemplateï¼ˆMicroscopeç‰ˆæœ¬ï¼‰

### Model 2: DataPoint (æ•°æ®ç‚¹)

**Purpose:** è¡¨ç¤ºä»è®ºæ–‡ä¸­æå–çš„å•ä¸ªæ•°æ®å­—æ®µï¼Œå¸¦æœ‰ä¸‰è‰²æ ‡ç­¾ç³»ç»Ÿã€‚

**Key Attributes:**
- `variable_name`: String - å˜é‡åç§°
- `value`: Any - æå–çš„å€¼
- `source_label`: Enum["ğŸŸ¢", "ğŸŸ¡", "ğŸ”´"] - ä¸‰è‰²æ¥æºæ ‡ç­¾
- `evidence`: String - è¯æ®è¯´æ˜ï¼ˆé¡µç ã€ç« èŠ‚ã€è®¡ç®—è¿‡ç¨‹ï¼‰

### Model 3: Project (Meta-analysis é¡¹ç›®)

**Purpose:** è¡¨ç¤ºä¸€ä¸ªå®Œæ•´çš„ Meta-analysis é¡¹ç›®ï¼ŒåŒ…å«å¤šä¸ªæ•°æ®å¡ç‰‡å’Œé¡¹ç›®é…ç½®ã€‚

**Key Attributes:**
- `project_id`: String - é¡¹ç›®å”¯ä¸€æ ‡è¯†ç¬¦
- `name`: String - é¡¹ç›®åç§°
- `research_question`: String - ç ”ç©¶é—®é¢˜
- `created_date`: DateTime - åˆ›å»ºæ—¥æœŸ
- `data_cards_path`: Path - æ•°æ®å¡ç‰‡å­˜å‚¨è·¯å¾„
- `extraction_criteria`: Dict[String, Any] - æ•°æ®æå–æ ‡å‡†
- `quality_checklist_module`: String - ä½¿ç”¨çš„è´¨é‡æ£€æŸ¥è¡¨æ¨¡å—

**Relationships:**
- åŒ…å«å¤šä¸ª DataCardï¼ˆä¸€å¯¹å¤šï¼‰
- åŒ…å«å¤šä¸ª CompiledDatasetï¼ˆä¸€å¯¹å¤šï¼‰
- åŒ…å«å¤šä¸ª Analysisï¼ˆä¸€å¯¹å¤šï¼‰

### Model 4: CompiledDataset (ç¼–è¯‘æ•°æ®é›†)

**Purpose:** è¡¨ç¤ºä»å¤šä¸ªæ•°æ®å¡ç‰‡èšåˆè€Œæˆçš„ç»Ÿä¸€æ•°æ®é›†ã€‚

**Key Attributes:**
- `dataset_id`: String - æ•°æ®é›†å”¯ä¸€æ ‡è¯†ç¬¦
- `name`: String - æ•°æ®é›†åç§°
- `created_date`: DateTime - åˆ›å»ºæ—¥æœŸ
- `compiler_version`: String - ä½¿ç”¨çš„ Compiler prompt ç‰ˆæœ¬
- `source_data_cards`: List[String] - æºæ•°æ®å¡ç‰‡è·¯å¾„åˆ—è¡¨
- `data_quality_summary`: Dict[String, Float] - æ•°æ®è´¨é‡æ±‡æ€»

### Model 5: PromptTemplate (Prompt æ¨¡æ¿)

**Purpose:** è¡¨ç¤ºç‰ˆæœ¬åŒ–çš„ prompt æ¨¡æ¿ï¼Œæ”¯æŒ RAAA å¯é‡ç°æ€§è¦æ±‚ã€‚

**Key Attributes:**
- `template_id`: String - æ¨¡æ¿å”¯ä¸€æ ‡è¯†ç¬¦
- `name`: String - æ¨¡æ¿åç§°
- `version`: String - ç‰ˆæœ¬å·ï¼ˆSemVeræ ¼å¼ï¼‰
- `type`: Enum["microscope", "compiler", "oracle"] - æ¨¡æ¿ç±»å‹
- `compatible_models`: List[String] - å…¼å®¹çš„ Claude æ¨¡å‹åˆ—è¡¨
- `template_content`: String - Prompt å†…å®¹

### Model 6: Analysis (ç»Ÿè®¡åˆ†æ)

**Purpose:** è¡¨ç¤º Oracle ç”Ÿæˆçš„ç»Ÿè®¡åˆ†æï¼ŒåŒ…æ‹¬ä»£ç å’Œç»“æœè§£é‡Šã€‚

**Key Attributes:**
- `analysis_id`: String - åˆ†æå”¯ä¸€æ ‡è¯†ç¬¦
- `name`: String - åˆ†æåç§°
- `research_question`: String - ç ”ç©¶é—®é¢˜ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
- `oracle_version`: String - ä½¿ç”¨çš„ Oracle prompt ç‰ˆæœ¬
- `language`: Enum["r", "python"] - ä»£ç è¯­è¨€
- `code`: String - ç”Ÿæˆçš„åˆ†æä»£ç 
- `interpretation`: String - AI ç”Ÿæˆçš„ç»“æœè§£é‡Š

### Model 7: ConversationLog (å¯¹è¯æ—¥å¿—) - CROS é˜¶æ®µ

**Purpose:** è®°å½•ç”¨æˆ·ä¸ Claude Code çš„äº¤äº’å†å²ï¼Œæ”¯æŒæˆæœ¬è¿½è¸ªåŠŸèƒ½ã€‚

**Key Attributes:**
- `log_id`: String - æ—¥å¿—å”¯ä¸€æ ‡è¯†ç¬¦
- `project_id`: String - å…³è”é¡¹ç›®ID
- `timestamp`: DateTime - å¯¹è¯æ—¶é—´
- `prompt_template_id`: String - ä½¿ç”¨çš„æ¨¡æ¿ID
- `tokens_used`: Integer - ä½¿ç”¨çš„ token æ•°é‡
- `model_version`: String - ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬
- `cost_estimate`: Float - ä¼°è®¡æˆæœ¬ï¼ˆç¾å…ƒï¼‰

### Model 8: QualityAssessment (è´¨é‡è¯„ä¼°)

**Purpose:** è¡¨ç¤ºå¯¹å•ç¯‡ç ”ç©¶çš„è´¨é‡è¯„ä¼°ç»“æœã€‚

**Key Attributes:**
- `assessment_id`: String - è¯„ä¼°å”¯ä¸€æ ‡è¯†ç¬¦
- `data_card_id`: String - å…³è”çš„æ•°æ®å¡ç‰‡ID
- `checklist_module`: String - ä½¿ç”¨çš„æ£€æŸ¥è¡¨
- `scores`: Dict[String, Any] - è¯„ä¼°åˆ†æ•°
- `overall_quality`: Enum["high", "medium", "low"] - æ€»ä½“è´¨é‡è¯„çº§

### Data Model Relationships

```mermaid
erDiagram
    Project ||--o{ DataCard : contains
    Project ||--o{ CompiledDataset : contains
    Project ||--o{ Analysis : contains
    Project ||--o{ ConversationLog : contains

    DataCard ||--o{ DataPoint : contains
    DataCard ||--|| QualityAssessment : has
    DataCard }o--|| PromptTemplate : uses

    CompiledDataset }o--o{ DataCard : aggregates
    CompiledDataset ||--o{ Analysis : used_by

    Analysis }o--|| PromptTemplate : uses

    ConversationLog }o--|| PromptTemplate : references

    Project {
        string project_id PK
        string name
        string research_question
        datetime created_date
    }

    DataCard {
        string study_id PK
        string title
        list authors
        int year
        datetime extraction_date
    }

    DataPoint {
        string variable_name
        any value
        enum source_label
        string evidence
    }
```

---

## Components

åŸºäºæ¶æ„æ¨¡å¼ã€æŠ€æœ¯æ ˆå’Œæ•°æ®æ¨¡å‹ï¼ŒMAestro ç³»ç»Ÿç”±ä»¥ä¸‹é€»è¾‘ç»„ä»¶ç»„æˆï¼ˆä¸»è¦é’ˆå¯¹ CROS é˜¶æ®µï¼‰ã€‚

### Component 1: Prompt Template Manager

**Responsibility:** ç®¡ç†ç‰ˆæœ¬åŒ–çš„ prompt æ¨¡æ¿ï¼ˆMicroscope, Compiler, Oracleï¼‰ï¼Œæ”¯æŒåŠ è½½ã€ç‰ˆæœ¬é€‰æ‹©ã€å‚æ•°æ³¨å…¥å’Œå…¼å®¹æ€§æ£€æŸ¥ã€‚

**Key Interfaces:**
- `load_template(template_type: str, version: str) -> PromptTemplate`
- `list_templates(template_type: str = None) -> List[PromptTemplate]`
- `validate_compatibility(template_id: str, model_version: str) -> bool`
- `inject_parameters(template: PromptTemplate, params: Dict) -> str`

**Dependencies:** Filesystem, SQLite (CROS), PyYAML

**Technology Stack:** Python 3.9+, Pydantic, Jinja2 (optional)

### Component 2: Data Card Parser & Writer

**Responsibility:** è§£æ markdown æ•°æ®å¡ç‰‡æ–‡ä»¶ä¸ºç»“æ„åŒ– DataCard å¯¹è±¡ï¼Œå¹¶å°†å¯¹è±¡åºåˆ—åŒ–å› markdownã€‚

**Key Interfaces:**
- `parse_data_card(file_path: Path) -> DataCard`
- `write_data_card(data_card: DataCard, file_path: Path) -> None`
- `extract_data_points(markdown_table: str) -> List[DataPoint]`
- `parse_source_label(label_str: str) -> SourceLabel`

**Dependencies:** Filesystem, PyYAML, python-markdown, Pydantic

**Technology Stack:** Python 3.9+, python-markdown + è¡¨æ ¼æ‰©å±•

### Component 3: Schema Validator

**Responsibility:** éªŒè¯æ•°æ®å¡ç‰‡ã€ç¼–è¯‘æ•°æ®é›†å’Œå…¶ä»–æ•°æ®ç»“æ„ç¬¦åˆå®šä¹‰çš„ schemaã€‚

**Key Interfaces:**
- `validate_data_card(data_card: DataCard) -> ValidationResult`
- `validate_compiled_dataset(dataset_path: Path) -> ValidationResult`
- `check_required_fields(data_card: DataCard, criteria: Dict) -> List[str]`

**Dependencies:** Pydantic, pandas, Data Card Parser

**Technology Stack:** Python 3.9+ with type hints, Pydantic v2.6+

### Component 4: Compiler Engine

**Responsibility:** èšåˆå¤šä¸ªæ•°æ®å¡ç‰‡ä¸ºç»Ÿä¸€çš„ CSV/TSV æ•°æ®é›†ï¼Œå¤„ç†å¼‚æ„æ•°æ®ç»“æ„ï¼Œç”Ÿæˆæ•°æ®è´¨é‡æ‘˜è¦ã€‚

**Key Interfaces:**
- `compile_dataset(data_cards: List[Path], output_path: Path) -> CompiledDataset`
- `infer_schema(data_cards: List[DataCard]) -> Dict`
- `generate_quality_summary(dataset: CompiledDataset) -> Dict`

**Dependencies:** Data Card Parser, pandas, Schema Validator

**Technology Stack:** Python 3.9+, pandas 2.2+, numpy

### Component 5: Oracle Analysis Generator

**Responsibility:** å°†è‡ªç„¶è¯­è¨€ç ”ç©¶é—®é¢˜è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„ R æˆ– Python ç»Ÿè®¡åˆ†æä»£ç ã€‚

**Key Interfaces:**
- `generate_analysis_code(question: str, dataset_path: Path, language: str) -> Analysis`
- `interpret_results(code: str, output: str) -> str`
- `suggest_sensitivity_analyses(dataset: CompiledDataset) -> List[str]`

**Dependencies:** Prompt Template Manager, Compiled Dataset

**Technology Stack:** Python 3.9+, ast module (Python code validation)

### Component 6: Project Manager

**Responsibility:** ç®¡ç† Meta-analysis é¡¹ç›®çš„é…ç½®ã€å…ƒæ•°æ®å’ŒçŠ¶æ€è·Ÿè¸ªã€‚

**Key Interfaces:**
- `create_project(name: str, research_question: str, config: Dict) -> Project`
- `load_project(project_path: Path) -> Project`
- `update_project_status(project_id: str, status: str) -> None`
- `list_data_cards(project_id: str) -> List[Path]`

**Dependencies:** SQLite (CROS), Filesystem, PyYAML

**Technology Stack:** Python 3.9+, SQLite3, pathlib

### Component 7: Conversation Logger (CROS Only)

**Responsibility:** è®°å½•ç”¨æˆ·ä¸ Claude Code çš„å¯¹è¯å†å²ï¼Œæ”¯æŒæˆæœ¬è¿½è¸ªå’Œå®¡è®¡ã€‚

**Key Interfaces:**
- `log_conversation(project_id: str, user_msg: str, metadata: Dict) -> None`
- `get_conversation_history(project_id: str, limit: int) -> List[ConversationLog]`
- `calculate_project_cost(project_id: str) -> float`

**Dependencies:** SQLite

**Technology Stack:** Python 3.9+, SQLite3, JSON

### Component 8: CLI Interface (Python CLI)

**Responsibility:** æä¾›å‘½ä»¤è¡Œç•Œé¢ï¼Œæš´éœ² MAestro æ ¸å¿ƒåŠŸèƒ½ä¸º CLI å‘½ä»¤ã€‚

**Key Interfaces:**
- `maestro init <project_name>`
- `maestro microscope <paper.pdf>`
- `maestro compile [--output compiled.csv]`
- `maestro oracle "<question>"`
- `maestro validate [--fix]`

**Dependencies:** æ‰€æœ‰ä¸Šè¿°æ ¸å¿ƒç»„ä»¶, Typer, Rich

**Technology Stack:** Python 3.9+, Typer 0.12+, Rich 13.7+

### Component 9: VS Code Extension (TypeScript)

**Responsibility:** æä¾›å›¾å½¢åŒ–å¯¹è¯ç•Œé¢ï¼Œé›†æˆåˆ° VS Code ç¼–è¾‘å™¨ã€‚

**Key Interfaces:**
- Webview Panel: å¯¹è¯å¼ UI
- Editor Integration: æ•°æ®å¡ç‰‡è¯­æ³•é«˜äº®
- Command Palette: VS Code å‘½ä»¤

**Dependencies:** VS Code Extension API, Python CLI (subprocess)

**Technology Stack:** TypeScript 5.4+, VS Code Extension API 1.88+, esbuild

### Component Diagram

```mermaid
graph TB
    subgraph "User Interfaces"
        CLI[CLI Interface<br/>Typer + Rich]
        VSCode[VS Code Extension<br/>TypeScript]
    end

    subgraph "Core Application Layer"
        PTM[Prompt Template Manager]
        DCP[Data Card Parser & Writer]
        SV[Schema Validator]
        CE[Compiler Engine]
        OAG[Oracle Analysis Generator]
        PM[Project Manager]
        CL[Conversation Logger]
    end

    subgraph "Data Layer"
        FS[(Filesystem<br/>Data Cards, Prompts)]
        DB[(SQLite<br/>Metadata, Logs)]
    end

    subgraph "External Services"
        CC[Claude Code<br/>User's Installation]
    end

    CLI --> PTM
    CLI --> DCP
    CLI --> CE
    CLI --> OAG
    CLI --> PM

    VSCode -.->|subprocess| CLI

    PTM --> FS
    DCP --> FS
    CE --> DCP
    CE --> SV
    OAG --> PTM
    PM --> DB
    PM --> FS
    CL --> DB

    DCP --> SV

    User -.->|manually runs prompts| CC

    style CLI fill:#e1f5ff
    style VSCode fill:#e1f5ff
    style CC fill:#fff4e1
    style FS fill:#e8f5e9
    style DB fill:#e8f5e9
```

---

## External APIs

MAestro é‡‡ç”¨ **æœ€å°å¤–éƒ¨ä¾èµ–** åŸåˆ™ï¼Œæœ¬åœ°ä¼˜å…ˆæ¶æ„æ„å‘³ç€å¤§éƒ¨åˆ†åŠŸèƒ½åœ¨ç”¨æˆ·æœ¬åœ°å®Œæˆã€‚

### API 1: Claude Code (å†…ç½® AI æ¨¡å‹è°ƒç”¨)

- **Purpose:** æ ¸å¿ƒ AI åŠŸèƒ½ - è®ºæ–‡åˆ†æã€æ•°æ®æå–ã€ç»Ÿè®¡ä»£ç ç”Ÿæˆ
- **Documentation:** Claude Code å®˜æ–¹æ–‡æ¡£
- **Base URL(s):** N/Aï¼ˆé€šè¿‡ Claude Code CLI/Desktop åº”ç”¨å†…ç½®è°ƒç”¨ï¼‰
- **Authentication:** ç”± Claude Code ç®¡ç†ï¼ˆç”¨æˆ·æ— éœ€å•ç‹¬é…ç½® API keyï¼‰
- **Rate Limits:** ç”± Claude Code/Anthropic è´¦æˆ·é™åˆ¶å†³å®š

**Integration Notes:**

**MVP é˜¶æ®µï¼š** ç”¨æˆ·æ‰‹åŠ¨å°† prompt æ¨¡æ¿å†…å®¹å¤åˆ¶åˆ° Claude Code ä¼šè¯

**CROS é˜¶æ®µå¯èƒ½çš„é›†æˆæ–¹å¼ï¼š**
- **é€‰é¡¹ A:** è°ƒç”¨ Claude Code CLIï¼ˆå¦‚æœæ”¯æŒï¼‰
- **é€‰é¡¹ B:** ä½¿ç”¨ Claude Code ä½œä¸º MCP Server
- **é€‰é¡¹ C:** ä»… prompt ç®¡ç†ï¼ˆç”¨æˆ·æ‰‹åŠ¨æ‰§è¡Œï¼‰- **å½“å‰é‡‡ç”¨**

**å½“å‰æ¶æ„å»ºè®®ï¼š** é€‰é¡¹ C - CROS å·¥å…·ä½œä¸º"prompt ç®¡ç†å’Œæ•°æ®å·¥å…·"ï¼Œä¸æ˜¯"AI è°ƒç”¨åŒ…è£…å™¨"

### API 2: GitHub APIï¼ˆå¯é€‰ - CROS Phase 2ï¼‰

- **Purpose:** ç¤¾åŒºæ¨¡å—å‘ç°å’Œä¸‹è½½
- **Documentation:** https://docs.github.com/en/rest
- **Base URL(s):** https://api.github.com
- **Authentication:** Public read access (æ— éœ€è®¤è¯ï¼Œå—é™ 60 req/hr)
- **Rate Limits:** Unauthenticated: 60 requests/hour

**å®ç°ä¼˜å…ˆçº§ï¼š** â¬‡ï¸ ä½ï¼ˆEpic 3 ä¹‹åï¼Œç¤¾åŒºå¢é•¿é˜¶æ®µï¼‰

---

## Core Workflows

ä»¥ä¸‹åºåˆ—å›¾å±•ç¤º MAestro çš„å…³é”®ç³»ç»Ÿå·¥ä½œæµã€‚

### Workflow 1: Microscope - å•ç¯‡è®ºæ–‡æ•°æ®æå– (CROS é˜¶æ®µ)

```mermaid
sequenceDiagram
    actor User as ç ”ç©¶è€…
    participant CLI as MAestro CLI
    participant PTM as Prompt Template Manager
    participant CC as Claude Code
    participant DCP as Data Card Parser
    participant SV as Schema Validator
    participant FS as æ–‡ä»¶ç³»ç»Ÿ

    User->>CLI: maestro microscope paper.pdf --study-id study_001
    CLI->>PTM: load_template("microscope", "v1.0")
    PTM->>FS: è¯»å– prompts/microscope_v1.md
    FS-->>PTM: è¿”å›æ¨¡æ¿å†…å®¹
    PTM-->>CLI: è¿”å›å®Œæ•´ prompt

    CLI->>User: ğŸ”µ è¯·åœ¨ Claude Code ä¸­è¿è¡Œä»¥ä¸‹ prompt
    User->>CC: ç²˜è´´ prompt + è®ºæ–‡æ–‡æœ¬
    CC->>CC: åˆ†æè®ºæ–‡
    CC-->>User: è¿”å› markdown æ ¼å¼æ•°æ®å¡ç‰‡
    User->>CLI: ç²˜è´´ AI å“åº”

    CLI->>DCP: parse_data_card(ai_response)
    DCP-->>CLI: è¿”å› DataCard å¯¹è±¡

    CLI->>SV: validate_data_card(data_card)
    alt éªŒè¯å¤±è´¥
        SV-->>CLI: ValidationError
        CLI-->>User: âŒ éªŒè¯å¤±è´¥ï¼šç¼ºå°‘ 'sample_size' å­—æ®µ
    else éªŒè¯æˆåŠŸ
        SV-->>CLI: ValidationResult(success=True)
        CLI->>FS: å†™å…¥ data_cards/study_001.md
        CLI-->>User: âœ… æ•°æ®å¡ç‰‡å·²ä¿å­˜<br/>ğŸ“Š æ•°æ®è´¨é‡ï¼šğŸŸ¢ 85%, ğŸŸ¡ 12%, ğŸ”´ 3%
    end
```

### Workflow 2: Compiler - æ•°æ®é›†ç¼–è¯‘

```mermaid
sequenceDiagram
    actor User as ç ”ç©¶è€…
    participant CLI as MAestro CLI
    participant PM as Project Manager
    participant DCP as Data Card Parser
    participant CE as Compiler Engine
    participant FS as æ–‡ä»¶ç³»ç»Ÿ

    User->>CLI: maestro compile --output compiled_data.csv
    CLI->>PM: list_data_cards(project_id)
    PM->>FS: æ‰«æ data_cards/ ç›®å½•
    FS-->>PM: è¿”å›æ•°æ®å¡ç‰‡è·¯å¾„åˆ—è¡¨

    CLI->>User: ğŸ“ å‘ç° 15 ä¸ªæ•°æ®å¡ç‰‡ï¼Œå¼€å§‹ç¼–è¯‘...

    loop æ¯ä¸ªæ•°æ®å¡ç‰‡
        CLI->>DCP: parse_data_card(file_path)
        DCP->>FS: è¯»å–æ–‡ä»¶
        FS-->>DCP: è¿”å› markdown å†…å®¹
        DCP-->>CLI: è¿”å› DataCard å¯¹è±¡
    end

    CLI->>CE: compile_dataset(data_cards, output_path)
    CE->>CE: èšåˆæ•°æ®ç‚¹åˆ° DataFrame
    CE->>FS: å†™å…¥ CSV æ–‡ä»¶

    CE->>CE: generate_quality_summary()
    CE-->>CLI: è¿”å›è´¨é‡æŠ¥å‘Š

    CLI-->>User: âœ… ç¼–è¯‘å®Œæˆï¼šcompiled_data.csv<br/>ğŸ“Š 15 ç¯‡è®ºæ–‡ï¼Œ245 ä¸ªæ•°æ®ç‚¹<br/>ğŸŸ¢ 85.7% ğŸŸ¡ 11.4% ğŸ”´ 2.9%
```

### Workflow 3: Oracle - ç»Ÿè®¡åˆ†æç”Ÿæˆ

```mermaid
sequenceDiagram
    actor User as ç ”ç©¶è€…
    participant CLI as MAestro CLI
    participant PTM as Prompt Template Manager
    participant CC as Claude Code
    participant OAG as Oracle Analysis Generator
    participant FS as æ–‡ä»¶ç³»ç»Ÿ

    User->>CLI: maestro oracle "What is the pooled effect size?" --language r
    CLI->>PTM: load_template("oracle", "v1.0")
    PTM-->>CLI: è¿”å› prompt

    CLI->>FS: è¯»å– compiled_data.csvï¼ˆè·å–æ•°æ®ä¸Šä¸‹æ–‡ï¼‰
    CLI->>OAG: prepare_oracle_prompt(question, dataset_context, language)
    OAG-->>CLI: è¿”å›å®Œæ•´ prompt

    CLI->>User: ğŸ”µ è¯·åœ¨ Claude Code ä¸­è¿è¡Œä»¥ä¸‹ prompt
    User->>CC: ç²˜è´´ prompt
    CC->>CC: ç”Ÿæˆ R ç»Ÿè®¡ä»£ç  + è§£é‡Š
    CC-->>User: è¿”å›ä»£ç å’Œè§£é‡Š

    User->>CLI: ç²˜è´´ AI ç”Ÿæˆçš„ä»£ç 
    CLI->>FS: å†™å…¥ analyses/pooled_effect.R
    CLI->>FS: å†™å…¥ analyses/pooled_effect_interpretation.md

    CLI-->>User: âœ… åˆ†æå·²ä¿å­˜<br/>ğŸ’¡ å»ºè®®ï¼šæ•°æ®åŒ…å« 2.9% ğŸ”´ æ ‡ç­¾æ•°æ®ï¼Œè€ƒè™‘æ•æ„Ÿæ€§åˆ†æ
```

### Workflow 4: ç«¯åˆ°ç«¯ Meta-analysis æµç¨‹

```mermaid
sequenceDiagram
    actor User as ç ”ç©¶è€…
    participant CLI as MAestro CLI
    participant FS as æ–‡ä»¶ç³»ç»Ÿ
    participant CC as Claude Code

    Note over User,CC: Phase 1: é¡¹ç›®åˆå§‹åŒ–
    User->>CLI: maestro init "Intervention-X-Meta-Analysis"
    CLI->>FS: åˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹ç»“æ„
    CLI-->>User: âœ… é¡¹ç›®å·²åˆ›å»º

    Note over User,CC: Phase 2: æ•°æ®æå–ï¼ˆ10-30 ç¯‡è®ºæ–‡ï¼‰
    loop å¯¹æ¯ç¯‡è®ºæ–‡
        User->>CLI: maestro microscope paper_N.pdf
        CLI->>User: æ˜¾ç¤º prompt
        User->>CC: æ‰§è¡Œæ•°æ®æå–
        CC-->>User: è¿”å›æ•°æ®å¡ç‰‡
        User->>CLI: æäº¤æ•°æ®å¡ç‰‡
        CLI->>FS: ä¿å­˜ data_cards/study_N.md
    end

    Note over User,CC: Phase 3: æ•°æ®éªŒè¯
    User->>CLI: maestro validate
    CLI-->>User: ğŸ“‹ éªŒè¯æŠ¥å‘Š

    Note over User,CC: Phase 4: æ•°æ®ç¼–è¯‘
    User->>CLI: maestro compile
    CLI->>FS: å†™å…¥ compiled/main_analysis.csv
    CLI-->>User: âœ… ç¼–è¯‘å®Œæˆ

    Note over User,CC: Phase 5: ç»Ÿè®¡åˆ†æ
    User->>CLI: maestro oracle "Pooled effect size"
    User->>CC: æ‰§è¡Œ Oracle prompt
    CC-->>User: ç”Ÿæˆ R ä»£ç 
    CLI->>FS: å†™å…¥ analyses/pooled_effect.R
```

---

## Database Schema

MAestro é‡‡ç”¨ **æ··åˆå­˜å‚¨æ¶æ„**ï¼šæ–‡ä»¶ç³»ç»Ÿå­˜å‚¨ç ”ç©¶æ•°æ®ï¼ˆä¸»è¦ï¼‰ï¼ŒSQLite å­˜å‚¨å…ƒæ•°æ®å’Œæ—¥å¿—ï¼ˆè¾…åŠ©ï¼Œä»… CROS é˜¶æ®µï¼‰ã€‚

**æ•°æ®åº“æ–‡ä»¶ä½ç½®ï¼š** `<project_root>/.maestro/maestro.db`

### Table 1: projects

```sql
CREATE TABLE projects (
    project_id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    research_question TEXT NOT NULL,
    created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    data_cards_path TEXT DEFAULT 'data_cards',
    compiled_datasets_path TEXT DEFAULT 'compiled',
    analyses_path TEXT DEFAULT 'analyses',
    extraction_criteria TEXT,
    quality_checklist_module TEXT DEFAULT 'generic',
    status TEXT CHECK(status IN ('planning', 'extracting', 'analyzing', 'complete')) DEFAULT 'planning',
    total_data_cards INTEGER DEFAULT 0,
    total_compilations INTEGER DEFAULT 0,
    total_analyses INTEGER DEFAULT 0
);
```

### Table 2: conversation_logs

```sql
CREATE TABLE conversation_logs (
    log_id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    prompt_template_id TEXT,
    prompt_type TEXT CHECK(prompt_type IN ('microscope', 'compiler', 'oracle', 'custom')),
    model_version TEXT NOT NULL,
    input_tokens INTEGER,
    output_tokens INTEGER,
    estimated_cost_usd REAL,
    context_items TEXT,
    data_card_id TEXT,
    success BOOLEAN DEFAULT TRUE,
    error_message TEXT,
    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE
);
```

### Table 3: prompt_templates

```sql
CREATE TABLE prompt_templates (
    template_id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    version TEXT NOT NULL,
    type TEXT CHECK(type IN ('microscope', 'compiler', 'oracle')) NOT NULL,
    file_path TEXT NOT NULL,
    compatible_models TEXT NOT NULL,
    created_date TIMESTAMP,
    description TEXT,
    parameters TEXT,
    usage_count INTEGER DEFAULT 0,
    UNIQUE(name, version)
);
```

### Table 4: data_card_metadata

```sql
CREATE TABLE data_card_metadata (
    data_card_id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    file_path TEXT NOT NULL,
    file_hash TEXT,
    last_modified TIMESTAMP,
    title TEXT,
    authors TEXT,
    year INTEGER,
    doi TEXT,
    extraction_date TIMESTAMP,
    extractor TEXT,
    microscope_version TEXT,
    screening_decision TEXT CHECK(screening_decision IN ('include', 'exclude')),
    overall_quality TEXT CHECK(overall_quality IN ('high', 'medium', 'low')),
    total_data_points INTEGER,
    green_count INTEGER,
    yellow_count INTEGER,
    red_count INTEGER,
    validation_status TEXT CHECK(validation_status IN ('valid', 'warning', 'error', 'not_validated')) DEFAULT 'not_validated',
    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE
);
```

### Table 5: compiled_datasets

```sql
CREATE TABLE compiled_datasets (
    dataset_id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    name TEXT NOT NULL,
    file_path TEXT NOT NULL,
    created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    compiler_version TEXT,
    source_data_cards TEXT NOT NULL,
    output_format TEXT CHECK(output_format IN ('csv', 'tsv')) DEFAULT 'csv',
    row_count INTEGER,
    green_percentage REAL,
    yellow_percentage REAL,
    red_percentage REAL,
    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE
);
```

### Table 6: analyses

```sql
CREATE TABLE analyses (
    analysis_id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    dataset_id TEXT,
    name TEXT NOT NULL,
    created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    research_question TEXT NOT NULL,
    oracle_version TEXT,
    language TEXT CHECK(language IN ('r', 'python')) NOT NULL,
    code_file_path TEXT NOT NULL,
    interpretation_file_path TEXT,
    executed BOOLEAN DEFAULT FALSE,
    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE,
    FOREIGN KEY (dataset_id) REFERENCES compiled_datasets(dataset_id) ON DELETE SET NULL
);
```

### æ–‡ä»¶ç³»ç»Ÿ vs æ•°æ®åº“èŒè´£åˆ’åˆ†

| æ•°æ®ç±»å‹ | å­˜å‚¨ä½ç½® | çœŸå®æ¥æº | å¯é‡å»ºï¼Ÿ |
|---------|---------|---------|---------|
| **æ•°æ®å¡ç‰‡å†…å®¹** | æ–‡ä»¶ç³»ç»Ÿ (.md) | âœ… æ˜¯ | âŒ å¦ï¼ˆæ ¸å¿ƒæ•°æ®ï¼‰ |
| **æ•°æ®å¡ç‰‡å…ƒæ•°æ®** | SQLite | âŒ å¦ | âœ… æ˜¯ï¼ˆæ‰«æ .md æ–‡ä»¶ï¼‰ |
| **ç¼–è¯‘æ•°æ®é›†** | æ–‡ä»¶ç³»ç»Ÿ (.csv) | âœ… æ˜¯ | âœ… æ˜¯ï¼ˆé‡æ–°ç¼–è¯‘ï¼‰ |
| **Prompt æ¨¡æ¿** | æ–‡ä»¶ç³»ç»Ÿ (.md) | âœ… æ˜¯ | âŒ å¦ï¼ˆæ ¸å¿ƒèµ„äº§ï¼‰ |
| **å¯¹è¯æ—¥å¿—** | SQLite | âœ… æ˜¯ | âŒ å¦ï¼ˆå†å²è®°å½•ï¼‰ |

---

## Source Tree

MAestro é‡‡ç”¨ **Monorepo ç»“æ„**ï¼ŒåŒ…å« prompt æ¨¡æ¿ã€æ–‡æ¡£ã€CROS å·¥å…·å’Œç¤ºä¾‹é¡¹ç›®ã€‚

```plaintext
maestro/                                    # ä»“åº“æ ¹ç›®å½•
â”‚
â”œâ”€â”€ .github/                                # GitHub é…ç½®
â”‚   â””â”€â”€ workflows/                          # CI/CD workflows
â”‚       â”œâ”€â”€ test.yml
â”‚       â”œâ”€â”€ publish-cli.yml
â”‚       â””â”€â”€ publish-extension.yml
â”‚
â”œâ”€â”€ prompts/                                # âœ¨ MVP æ ¸å¿ƒï¼šPrompt æ¨¡æ¿
â”‚   â”œâ”€â”€ microscope/
â”‚   â”‚   â”œâ”€â”€ microscope_v1.0.md
â”‚   â”‚   â””â”€â”€ CHANGELOG.md
â”‚   â”œâ”€â”€ compiler/
â”‚   â”‚   â”œâ”€â”€ compiler_v1.0.md
â”‚   â”‚   â””â”€â”€ CHANGELOG.md
â”‚   â””â”€â”€ oracle/
â”‚       â”œâ”€â”€ oracle_v1.0.md
â”‚       â””â”€â”€ CHANGELOG.md
â”‚
â”œâ”€â”€ modules/                                # å­¦ç§‘ç‰¹å®šè´¨é‡æ£€æŸ¥è¡¨
â”‚   â”œâ”€â”€ generic/
â”‚   â”‚   â””â”€â”€ generic_quality_checklist.md
â”‚   â””â”€â”€ rob2/
â”‚       â””â”€â”€ rob2_checklist.md
â”‚
â”œâ”€â”€ templates/                              # æ–‡ä»¶æ¨¡æ¿
â”‚   â”œâ”€â”€ data_card.md
â”‚   â”œâ”€â”€ raaa_appendix.md
â”‚   â””â”€â”€ project_config.yaml
â”‚
â”œâ”€â”€ docs/                                   # ğŸ“š æ–‡æ¡£
â”‚   â”œâ”€â”€ index.md
â”‚   â”œâ”€â”€ quickstart.md
â”‚   â”œâ”€â”€ best-practices.md
â”‚   â”œâ”€â”€ architecture.md                    # æœ¬æ–‡æ¡£
â”‚   â””â”€â”€ api/
â”‚
â”œâ”€â”€ tools/                                  # ğŸ”§ CROS å·¥å…·
â”‚   â”œâ”€â”€ cli/                                # Python CLI
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”œâ”€â”€ maestro/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cli.py
â”‚   â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚       â”œâ”€â”€ unit/
â”‚   â”‚       â”œâ”€â”€ integration/
â”‚   â”‚       â””â”€â”€ fixtures/
â”‚   â”‚
â”‚   â””â”€â”€ vscode-extension/                   # VS Code Extension
â”‚       â”œâ”€â”€ package.json
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ extension.ts
â”‚       â”‚   â”œâ”€â”€ commands/
â”‚       â”‚   â”œâ”€â”€ webview/
â”‚       â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test/
â”‚
â”œâ”€â”€ tests/                                  # ğŸ§ª è·¨å·¥å…·éªŒè¯æµ‹è¯•
â”‚   â”œâ”€â”€ validation/
â”‚   â””â”€â”€ performance/
â”‚
â”œâ”€â”€ examples/                               # ğŸ“ ç¤ºä¾‹é¡¹ç›®
â”‚   â””â”€â”€ sample_meta_analysis/
â”‚       â”œâ”€â”€ data_cards/
â”‚       â”œâ”€â”€ compiled/
â”‚       â””â”€â”€ analyses/
â”‚
â”œâ”€â”€ scripts/                                # ğŸ”¨ ä»“åº“ç®¡ç†è„šæœ¬
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ mkdocs.yml
```

---

## Infrastructure and Deployment

MAestro é‡‡ç”¨ **æœ¬åœ°ä¼˜å…ˆæ¶æ„**ï¼Œæ— éœ€ä¼ ç»Ÿäº‘åŸºç¡€è®¾æ–½ã€‚"éƒ¨ç½²"æŒ‡çš„æ˜¯ **åˆ†å‘åŒ…åˆ°å…¬å…±ä»“åº“**ã€‚

### Infrastructure as Code

**å·¥å…·:** N/Aï¼ˆæ— äº‘åŸºç¡€è®¾æ–½ï¼‰

**è¯´æ˜:** MAestro æ˜¯æœ¬åœ°æ¡Œé¢åº”ç”¨ï¼Œä¸éœ€è¦äº‘æœåŠ¡å™¨ã€‚

### Deployment Strategy

#### 1. MVP Prompt æ¨¡æ¿ï¼ˆå³æ—¶å¯ç”¨ï¼‰

**éƒ¨ç½²æ–¹å¼:** Git ä»“åº“ç›´æ¥è®¿é—®

**å‘å¸ƒæµç¨‹:**
1. åˆ›å»ºæ–° prompt ç‰ˆæœ¬
2. æ›´æ–° CHANGELOG.md
3. æäº¤å¹¶ push
4. æ‰“ Git tag
5. åˆ›å»º GitHub Release

#### 2. Python CLIï¼ˆPyPI å‘å¸ƒï¼‰

**æ„å»ºå‘½ä»¤:**
```bash
cd tools/cli
poetry build
```

**å‘å¸ƒæµç¨‹ï¼ˆGitHub Actionsï¼‰:**
```yaml
# .github/workflows/publish-cli.yml
- name: Publish to PyPI
  env:
    POETRY_PYPI_TOKEN_PYPI: ${{ secrets.PYPI_TOKEN }}
  run: poetry publish
```

**ç”¨æˆ·å®‰è£…:**
```bash
pip install maestro-meta
```

#### 3. VS Code Extensionï¼ˆMarketplace å‘å¸ƒï¼‰

**æ„å»ºå‘½ä»¤:**
```bash
cd tools/vscode-extension
vsce package
```

**å‘å¸ƒæµç¨‹ï¼ˆGitHub Actionsï¼‰:**
```yaml
# .github/workflows/publish-extension.yml
- name: Publish to Marketplace
  env:
    VSCE_PAT: ${{ secrets.VSCODE_MARKETPLACE_TOKEN }}
  run: vsce publish
```

#### 4. æ–‡æ¡£ç«™ç‚¹ï¼ˆGitHub Pagesï¼‰

**æ„å»ºå·¥å…·:** MkDocs + Material ä¸»é¢˜

**éƒ¨ç½²ï¼ˆGitHub Actionsï¼‰:**
```yaml
# .github/workflows/deploy-docs.yml
- name: Build and deploy
  run: mkdocs gh-deploy --force
```

**è®¿é—®åœ°å€:** https://maestro-meta.github.io

### Environments

| Environment | Purpose | Details |
|-------------|---------|---------|
| **Development** | æœ¬åœ°å¼€å‘ | Poetry/npm install, çƒ­é‡è½½ |
| **CI Testing** | GitHub Actions è‡ªåŠ¨åŒ–æµ‹è¯• | è·¨å¹³å° matrix æµ‹è¯• |
| **User Production** | æœ€ç»ˆç”¨æˆ·æœ¬åœ°ç¯å¢ƒ | pip/VS Code Marketplace å®‰è£… |

### Rollback Strategy

**å›æ»šæ–¹æ³•:**

| ç»„ä»¶ | ç›®æ ‡ RTO | å›æ»šæ–¹æ³• |
|------|---------|---------|
| **Python CLI** | < 4 å°æ—¶ | å‘å¸ƒä¿®å¤ç‰ˆæœ¬æˆ–æŒ‡å¯¼ç”¨æˆ·é™çº§ |
| **VS Code Extension** | < 2 å°æ—¶ | Unpublish + é‡æ–°å‘å¸ƒæ—§ç‰ˆæœ¬ |
| **æ–‡æ¡£ç«™ç‚¹** | < 30 åˆ†é’Ÿ | Git revert + é‡æ–°éƒ¨ç½² |
| **Prompt æ¨¡æ¿** | ç«‹å³ | ç”¨æˆ·åˆ‡æ¢åˆ°æ—§ç‰ˆæœ¬ï¼ˆæ— éœ€å›æ»šï¼‰ |

---

## Error Handling Strategy

MAestro çš„é”™è¯¯å¤„ç†ç­–ç•¥ä¼˜å…ˆè€ƒè™‘ **ç”¨æˆ·å‹å¥½æ€§**å’Œ**å­¦æœ¯é€æ˜åº¦**ã€‚

### General Approach

**é”™è¯¯æ¨¡å‹:** ç»“æ„åŒ–å¼‚å¸¸ + ç”¨æˆ·å‹å¥½æ¶ˆæ¯

**å¼‚å¸¸å±‚æ¬¡ç»“æ„ï¼ˆPythonï¼‰:**

```python
class MaestroError(Exception):
    """æ‰€æœ‰ MAestro å¼‚å¸¸çš„åŸºç±»"""
    def __init__(self, message: str, suggestion: str = None, context: dict = None):
        self.message = message
        self.suggestion = suggestion
        self.context = context or {}

class DataCardParseError(MaestroError):
    """æ•°æ®å¡ç‰‡è§£æå¤±è´¥"""
    pass

class ValidationError(MaestroError):
    """æ•°æ®éªŒè¯å¤±è´¥"""
    pass

class CompilationError(MaestroError):
    """æ•°æ®ç¼–è¯‘å¤±è´¥"""
    pass
```

**é”™è¯¯ä¼ æ’­è§„åˆ™:**
- åº•å±‚å‡½æ•°ï¼šæŠ›å‡ºå…·ä½“å¼‚å¸¸
- ä¸­å±‚ç»„ä»¶ï¼šæ•è·å¹¶æ·»åŠ ä¸Šä¸‹æ–‡
- CLI å…¥å£ï¼šè½¬æ¢ä¸ºç”¨æˆ·å‹å¥½æ¶ˆæ¯

### Logging Standards

**æ—¥å¿—åº“:** Python `logging` + Rich handler

**æ—¥å¿—çº§åˆ«:**

| çº§åˆ« | ç”¨é€” | ç¤ºä¾‹ |
|------|------|------|
| DEBUG | è¯¦ç»†è°ƒè¯•ä¿¡æ¯ | "Parsing YAML frontmatter: 15 keys found" |
| INFO | æ­£å¸¸æ“ä½œ | "âœ… Data card saved" |
| WARNING | è­¦å‘Šä½†ä¸å½±å“æ‰§è¡Œ | "âš ï¸ Missing optional field 'doi'" |
| ERROR | é”™è¯¯ä½†å¯æ¢å¤ | "âŒ Validation failed" |
| CRITICAL | ä¸¥é‡é”™è¯¯ | "âŒ Cannot access database" |

**Required Context:**
- **Correlation ID:** æ¯ä¸ªå‘½ä»¤æ‰§è¡Œç”Ÿæˆå”¯ä¸€ ID
- **Service Context:** ç»„ä»¶åã€prompt ç‰ˆæœ¬ã€æ¨¡å‹ç‰ˆæœ¬
- **User Context:** é¡¹ç›® IDï¼ˆä¸è®°å½•ç ”ç©¶æ•°æ®ï¼‰

### Error Handling Patterns

#### Pattern 1: External API Errors (Claude Code)

ç”±äº MAestro ä¸ç›´æ¥è°ƒç”¨ APIï¼Œé”™è¯¯å¤„ç†ä¸»è¦æ˜¯æä¾›æŒ‡å¯¼ï¼š

```python
def handle_claude_code_error(error_type: str):
    suggestions = {
        'context_limit': "Paper exceeds context window. Try extracting only Methods and Results sections",
        'rate_limit': "API rate limit reached. Wait and retry",
    }
    raise ClaudeCodeIntegrationError(
        message=f"Claude Code error: {error_type}",
        suggestion=suggestions.get(error_type)
    )
```

#### Pattern 2: Business Logic Errors (éªŒè¯å¤±è´¥)

```python
class ValidationError(MaestroError):
    def __init__(self, errors: List[str], file_path: Path = None):
        self.errors = errors
        message = f"Validation failed with {len(errors)} error(s)"
        suggestion = "Add missing fields to data card YAML frontmatter"
        super().__init__(message, suggestion, {'file_path': str(file_path)})
```

**ç”¨æˆ·å‹å¥½é”™è¯¯ç¤ºä¾‹:**
```
âŒ Validation failed with 2 error(s)
ğŸ“ File: data_cards/study_003.md

Errors:
  1. Missing required field: 'sample_size'
  2. Invalid type for 'year': expected integer

ğŸ’¡ Suggestion: Check data types match the schema
ğŸ“š See docs/data-card-format.md
```

#### Pattern 3: Data Consistency (ç¼–è¯‘æ—¶å¼‚æ„æ•°æ®)

```python
def compile_dataset(data_cards: List[Path], output_path: Path):
    temp_output = output_path.with_suffix('.tmp')
    try:
        compiled_data = aggregate_data_cards(data_cards)
        compiled_data.to_csv(temp_output)
        validate_compiled_dataset(temp_output)
        temp_output.rename(output_path)
    except Exception as e:
        if temp_output.exists():
            temp_output.unlink()
        raise CompilationError(...)
```

### Logging Restrictions

**ä¸è¦è®°å½•:**
- âŒ è®ºæ–‡å®Œæ•´å†…å®¹
- âŒ æå–çš„ç ”ç©¶æ•°æ®
- âŒ ç”¨æˆ·çš„å®Œæ•´æ–‡ä»¶è·¯å¾„
- âŒ API keys

**å¯ä»¥è®°å½•:**
- âœ… æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
- âœ… æ“ä½œç±»å‹
- âœ… è®¡æ•°ç»Ÿè®¡
- âœ… æ€§èƒ½æŒ‡æ ‡

---

## Coding Standards

è¿™äº›æ ‡å‡†æ˜¯ **AI å¼€å‘ä»£ç†çš„å¼ºåˆ¶è§„åˆ™**ã€‚

### Core Standards

**Languages & Runtimes:**
- **Python:** 3.9+ with type hints (mandatory)
- **TypeScript:** 5.4+ with strict mode

**Style & Linting:**

Python:
```bash
poetry run black maestro/
poetry run ruff check maestro/
poetry run mypy maestro/
```

**Test Organization:**
```
tests/
  unit/test_{module}.py
  integration/test_{workflow}_workflow.py
  fixtures/{test_data}.md
```

### Naming Conventions

| Element | Python | TypeScript | Example |
|---------|--------|-----------|---------|
| **æ¨¡å—/æ–‡ä»¶** | snake_case | camelCase | `data_card.py`, `ChatPanel.ts` |
| **ç±»** | PascalCase | PascalCase | `DataCardParser` |
| **å‡½æ•°** | snake_case | camelCase | `parse_data_card()` |
| **å¸¸é‡** | UPPER_SNAKE_CASE | UPPER_SNAKE_CASE | `MAX_TOKEN_LIMIT` |

### Critical Rules

#### Rule 1: æ–‡ä»¶ç³»ç»Ÿæ˜¯çœŸå®æ¥æº

```python
# âœ… æ­£ç¡®ï¼šå†™å…¥æ–‡ä»¶ç³»ç»Ÿï¼Œæ•°æ®åº“ä»…å­˜ç´¢å¼•
def save_data_card(data_card: DataCard, file_path: Path):
    with open(file_path, 'w') as f:
        f.write(data_card.to_markdown())
    db.execute("INSERT INTO data_card_metadata ...")
```

#### Rule 2: ä¿ç•™ä¸‰è‰²æ ‡ç­¾å®Œæ•´æ€§

```python
# âœ… æ­£ç¡®ï¼šç¼–è¯‘æ—¶ä¿ç•™æ ‡ç­¾
def compile_data_points(data_cards: List[DataCard]) -> pd.DataFrame:
    data = []
    for card in data_cards:
        for point in card.extracted_data:
            data.append({
                'value': point.value,
                'source_label': point.source_label,  # ğŸŸ¢/ğŸŸ¡/ğŸ”´
            })
    return pd.DataFrame(data)
```

#### Rule 3: Prompt æ¨¡æ¿ç‰ˆæœ¬åŒ–

```bash
# âœ… æ­£ç¡®ï¼šåˆ›å»ºæ–°ç‰ˆæœ¬
cp microscope_v1.0.md microscope_v1.1.md
# ä¿®æ”¹æ–°ç‰ˆæœ¬æ–‡ä»¶
```

#### Rule 4: ç±»å‹å®‰å…¨ä¼˜å…ˆ

```python
# âœ… æ­£ç¡®ï¼šå®Œæ•´ç±»å‹æç¤º
def parse_data_card(file_path: Path) -> DataCard:
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    return DataCard.model_validate(data)
```

#### Rule 5: æ—¥å¿—ä¸å¾—åŒ…å«ç ”ç©¶æ•°æ®

```python
# âœ… æ­£ç¡®ï¼šä»…è®°å½•æ“ä½œ
logger.info(f"Extracted {len(data_points)} data points")
# âŒ é”™è¯¯ï¼šè®°å½•æ•æ„Ÿæ•°æ®
# logger.info(f"effect_size: {effect_size}")
```

#### Rule 6: ç”Ÿæˆçš„ä»£ç å¿…é¡»è‡ªåŒ…å«

```r
# âœ… æ­£ç¡®ï¼šåŒ…å«å®‰è£…è¯´æ˜
# Install required packages:
# install.packages(c("metafor", "readr"))

library(metafor)
library(readr)
# ... analysis code
```

#### Rule 7: è·¯å¾„å¿…é¡»è·¨å¹³å°å…¼å®¹

```python
# âœ… æ­£ç¡®ï¼šä½¿ç”¨ pathlib
from pathlib import Path
data_card_path = Path("data_cards") / f"{study_id}.md"
```

#### Rule 8: æ•°æ®å¡ç‰‡è§£æå¿…é¡»å®¹é”™

```python
# âœ… æ­£ç¡®ï¼šè½¬æ¢ä¸ºé¢†åŸŸå¼‚å¸¸
try:
    return yaml.safe_load(content)
except yaml.YAMLError as e:
    raise DataCardParseError(
        message="Invalid YAML frontmatter",
        suggestion="Check YAML syntax",
        context={'line': e.problem_mark.line}
    )
```

#### Rule 9: VS Code Extension è°ƒç”¨ Python CLI

```typescript
// âœ… æ­£ç¡®ï¼šè°ƒç”¨ CLI
async function parseDataCard(filePath: string): Promise<DataCard> {
  const result = await execAsync(`maestro parse-data-card "${filePath}"`);
  return JSON.parse(result.stdout);
}
```

#### Rule 10: å¼‚æ­¥æ“ä½œå¿…é¡»æ˜¾ç¤ºè¿›åº¦

```python
# âœ… æ­£ç¡®ï¼šæ˜¾ç¤ºè¿›åº¦
from rich.progress import track
for card_path in track(data_cards, description="Compiling..."):
    results.append(parse_data_card(card_path))
```

---

## Test Strategy and Standards

MAestro çš„æµ‹è¯•ç­–ç•¥å¹³è¡¡ **å­¦æœ¯ç ”ç©¶æ­£ç¡®æ€§** å’Œ **è½¯ä»¶å·¥ç¨‹è´¨é‡**ã€‚

### Testing Philosophy

**æ ¸å¿ƒåŸåˆ™:**
1. **éªŒè¯ä¼˜å…ˆäºè‡ªåŠ¨åŒ–ï¼ˆMVPï¼‰**
2. **æ¸è¿›å¼è‡ªåŠ¨åŒ–ï¼ˆCROSï¼‰**
3. **é‡‘æ ‡å‡†é©±åŠ¨**
4. **è·¨å¹³å°ä¿è¯**

**è¦†ç›–ç‡ç›®æ ‡:**

| é˜¶æ®µ | å•å…ƒæµ‹è¯•è¦†ç›–ç‡ | é›†æˆæµ‹è¯• | E2E æµ‹è¯• |
|------|---------------|---------|---------|
| **MVP** | N/Aï¼ˆæ— ä»£ç ï¼‰ | æ‰‹åŠ¨ | æ‰‹åŠ¨ |
| **CROS Phase 1** | 80%+ | è‡ªåŠ¨åŒ– | æ‰‹åŠ¨ |
| **CROS Phase 2** | 85%+ | è‡ªåŠ¨åŒ– | éƒ¨åˆ†è‡ªåŠ¨åŒ– |

### Test Types and Organization

#### 1. Unit Tests

**æ¡†æ¶:** pytest 8.0+ (Python), Jest (@vscode/test-electron)

**æµ‹è¯•ç»“æ„ï¼ˆAAA æ¨¡å¼ï¼‰:**
```python
def test_parse_valid_data_card(tmp_path):
    # Arrange
    parser = DataCardParser()
    file_path = tmp_path / "study_001.md"
    file_path.write_text(valid_content)

    # Act
    result = parser.parse(file_path)

    # Assert
    assert isinstance(result, DataCard)
    assert result.study_id == "study_001"
```

#### 2. Integration Tests

**æµ‹è¯•åŸºç¡€è®¾æ–½:**
- SQLite in-memory database
- ä¸´æ—¶æ–‡ä»¶ç³»ç»Ÿ

```python
def test_microscope_workflow_end_to_end(temp_project):
    prompt_manager = PromptTemplateManager()
    parser = DataCardParser()
    validator = SchemaValidator()

    # å®Œæ•´å·¥ä½œæµæµ‹è¯•
    prompt = prompt_manager.load_template('microscope', 'v1.0')
    # ...
    validation_result = validator.validate_data_card(data_card)
    assert validation_result.success
```

#### 3. End-to-End Tests

```python
def test_complete_meta_analysis_workflow(tmp_path):
    # 1. åˆå§‹åŒ–é¡¹ç›®
    subprocess.run(['maestro', 'init', 'test_project'], cwd=tmp_path)

    # 2. å¤„ç†è®ºæ–‡
    # 3. éªŒè¯
    # 4. ç¼–è¯‘
    # 5. åˆ†æ

    assert (project_dir / 'compiled' / 'test.csv').exists()
```

### Test Data Management

**Fixture ç»„ç»‡:**
```
tests/fixtures/
  sample_data_cards/valid/
  sample_data_cards/invalid/
  sample_papers/
  expected_outputs/
  claude_responses/
```

### Continuous Testing

**GitHub Actions:**
```yaml
jobs:
  test-python:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.9', '3.10', '3.11', '3.12']
    steps:
      - run: poetry run pytest --cov=maestro
```

---

## Security

MAestro çš„å®‰å…¨ç­–ç•¥ä¼˜å…ˆè€ƒè™‘ **å­¦æœ¯æ•°æ®éšç§** å’Œ **æœ¬åœ°ä¼˜å…ˆåŸåˆ™**ã€‚

### Input Validation

**å¿…éœ€è§„åˆ™:**

**1. æ–‡ä»¶è·¯å¾„éªŒè¯ï¼ˆé˜²æ­¢è·¯å¾„éå†ï¼‰:**
```python
def validate_safe_path(file_path: Path, base_dir: Path) -> Path:
    resolved = file_path.resolve()
    base_resolved = base_dir.resolve()

    if not str(resolved).startswith(str(base_resolved)):
        raise ValidationError("Path traversal detected")
    return resolved
```

**2. æ–‡ä»¶åæ¸…ç†:**
```python
def sanitize_filename(filename: str) -> str:
    safe_name = re.sub(r'[^a-zA-Z0-9_.-]', '_', filename)
    safe_name = safe_name.lstrip('.')
    return safe_name[:255]
```

**3. YAML å®‰å…¨åŠ è½½:**
```python
# âœ… ä½¿ç”¨ safe_load
return yaml.safe_load(content)
# âŒ ä¸ä½¿ç”¨ loadï¼ˆå¯æ‰§è¡Œä»£ç ï¼‰
```

**4. å‘½ä»¤æ³¨å…¥é˜²æŠ¤:**
```python
# âœ… å®‰å…¨ï¼šä½¿ç”¨åˆ—è¡¨å‚æ•°
subprocess.run(['maestro', arg1, arg2], shell=False)
# âŒ å±é™©ï¼šshell=True
```

### Authentication & Authorization

**é‡è¦:** MAestro æ˜¯æœ¬åœ°å•ç”¨æˆ·åº”ç”¨ï¼Œæ— éœ€ä¼ ç»Ÿç”¨æˆ·è®¤è¯ã€‚

**æ–‡ä»¶ç³»ç»Ÿæƒé™:**
```python
def create_secure_directory(path: Path, mode: int = 0o700):
    path.mkdir(mode=mode, parents=True, exist_ok=True)
```

### Secrets Management

**å…³é”®å†³ç­–:** MAestro é€šè¿‡ Claude Code è°ƒç”¨ AIï¼Œ**ä¸å­˜å‚¨ API keys**ã€‚

å¦‚æœæœªæ¥æ”¯æŒç›´æ¥ API è°ƒç”¨ï¼š
```python
import keyring

def store_api_key(key: str):
    keyring.set_password("maestro", "anthropic_api_key", key)

def retrieve_api_key() -> str:
    return keyring.get_password("maestro", "anthropic_api_key")
```

### Data Protection

**åŠ å¯† at Rest:** ä¾èµ– OS çº§åŠ å¯†ï¼ˆBitLocker, FileVault, LUKSï¼‰

**PII Handling:**
```python
# æ•°æ®å¡ç‰‡ä¸åº”åŒ…å« PII
# âš ï¸ è­¦å‘Šæ–‡æ¡£ï¼šä¸è¦åŒ…å«å‚ä¸è€…çº§åˆ«æ•°æ®
```

**Logging Restrictions:**
```python
class PrivacyAwareFilter(logging.Filter):
    REDACT_PATTERNS = [
        r'sk-ant-[a-zA-Z0-9]+',  # API keys
        r'\b\d{3}-\d{2}-\d{4}\b',  # SSN
    ]

    def filter(self, record):
        # ä¿®æ”¹æ—¥å¿—ï¼Œç§»é™¤æ•æ„Ÿä¿¡æ¯
        ...
```

### Dependency Security

**æ‰«æå·¥å…·:** `safety`, `pip-audit`, `npm audit`

**GitHub Actions:**
```yaml
- name: Run Safety check
  run: safety check --json

- name: Run npm audit
  run: npm audit --audit-level=moderate
```

**æ›´æ–°ç­–ç•¥:**

| æ¼æ´ä¸¥é‡æ€§ | å“åº”æ—¶é—´ | æ“ä½œ |
|----------|---------|------|
| Critical | 24 å°æ—¶ | ç´§æ€¥è¡¥ä¸ |
| High | 1 å‘¨ | è®¡åˆ’ä¿®å¤ |
| Moderate | 1 æœˆ | å®šæœŸæ›´æ–° |

### Security Testing

**SAST:**
```bash
# Python
bandit -r maestro/

# TypeScript
npm install --save-dev eslint-plugin-security
```

**æ‰‹åŠ¨å®‰å…¨æµ‹è¯•æ£€æŸ¥æ¸…å•:**
- [ ] è·¯å¾„éå†æµ‹è¯•
- [ ] æ¶æ„ YAML æµ‹è¯•
- [ ] ä¾èµ–æ¼æ´æ‰«æ
- [ ] æ—¥å¿—éšç§æ£€æŸ¥

---

## Summary

MAestro Architecture Document å®šä¹‰äº†ä» MVPï¼ˆçº¯ prompt æ¨¡æ¿ï¼‰åˆ° CROSï¼ˆæœ¬åœ°æ¡Œé¢åº”ç”¨ï¼‰çš„å®Œæ•´æŠ€æœ¯æ¶æ„ã€‚

**å…³é”®æ¶æ„å†³ç­–:**
- âœ… æœ¬åœ°ä¼˜å…ˆï¼ˆæ— äº‘æœåŠ¡å™¨ï¼‰
- âœ… æ–‡ä»¶ç³»ç»Ÿä¸ºä¸»è¦æ•°æ®å­˜å‚¨
- âœ… åŒé˜¶æ®µæ¼”è¿›ï¼ˆMVP â†’ CROSï¼‰
- âœ… ä¸‰è‰²æ ‡ç­¾ç³»ç»Ÿï¼ˆæ•°æ®è´¨é‡é€æ˜åº¦ï¼‰
- âœ… Monorepo ç»“æ„
- âœ… é€šè¿‡ Claude Code è°ƒç”¨ AIï¼ˆæ— éœ€å•ç‹¬ API key ç®¡ç†ï¼‰

**å®æ–½ä¼˜å…ˆçº§:** æŒ‰ PRD Epic é¡ºåºï¼ˆEpic 1 â†’ Epic 2 â†’ Epic 3ï¼‰

**åç»­æ­¥éª¤:**
1. æå– `tech-stack.md`, `coding-standards.md` ä¾› dev agent ä½¿ç”¨
2. å¼€å§‹ Epic 1 å®æ–½ï¼ˆä»“åº“åˆå§‹åŒ–ã€æ•°æ®å¡ç‰‡æ ¼å¼ã€Microscope promptï¼‰
3. å»ºç«‹ CI/CD pipelineï¼ˆGitHub Actionsï¼‰

---

**Document Status:** âœ… Complete
**Next Review:** Before Epic 1 implementation
